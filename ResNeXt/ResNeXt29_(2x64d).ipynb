{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNeXt 29 (2x64d)",
      "provenance": [],
      "authorship_tag": "ABX9TyPOTSChNqRtpZHX+DnJrKCe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/comb0703/practice/blob/main/ResNeXt29_(2x64d).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywJwgK--3K_f"
      },
      "source": [
        "import os\n",
        "import copy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjFnGIZw3cJt"
      },
      "source": [
        "if torch.cuda.is_available() :\n",
        "  device = torch.device('cuda')\n",
        "else : \n",
        "  print(\"error\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GY3ufOp3mTk",
        "outputId": "5e248b71-f7f5-410d-cc5f-c38d7fff1c94"
      },
      "source": [
        "transform = transforms.Compose([\n",
        "                                transforms.RandomCrop(32, padding=4),\n",
        "                                transforms.RandomHorizontalFlip(),\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "])\n",
        "\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data',\n",
        "                                             train = True,\n",
        "                                             download =True,\n",
        "                                             transform=transform)\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data',\n",
        "                                            train=False,\n",
        "                                            download=True,\n",
        "                                            transform = transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
        "                                           batch_size=64,\n",
        "                                           shuffle=True,\n",
        "                                           num_workers=4)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
        "                                          batch_size=64,\n",
        "                                          shuffle=False,\n",
        "                                          num_workers=4)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kd6mG6A86mYO"
      },
      "source": [
        "class ResNeXt(nn.Module) :\n",
        "  def __init__(self, num_classes=10) :\n",
        "    super(ResNeXt, self).__init__()\n",
        "\n",
        "\n",
        "    self.conv1 = nn.Conv2d(3,64,kernel_size=3,stride=1,padding=1,bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(64)\n",
        "   \n",
        "    # block 1 (in_plane = 64, plane = 256, c = 2, b_w = 64, g_w = 128\n",
        "    self.conv2 = nn.Conv2d(64,128,kernel_size=1,stride=1,padding=0,bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(128)\n",
        "    self.conv3 = nn.Conv2d(128,128,kernel_size=3,stride=1,padding=1,groups=2,bias=False)\n",
        "    self.bn3 = nn.BatchNorm2d(128)\n",
        "    self.conv4 = nn.Conv2d(128,256,kernel_size=1,stride=1,padding=0,bias=False)\n",
        "    self.bn4 = nn.BatchNorm2d(256)\n",
        "\n",
        "    self.shortcut1 = nn.Sequential(\n",
        "        nn.Conv2d(64, 256, kernel_size=1, stride=1, bias=False),\n",
        "        nn.BatchNorm2d(256)\n",
        "        )\n",
        "    # block 2 (in_plane = 256, plane = 128, c = 2, b_w = 64, g_w =128)\n",
        "    self.conv5 = nn.Conv2d(256,128,kernel_size=1,stride=1,padding=0,bias=False)\n",
        "    self.bn5 = nn.BatchNorm2d(128)\n",
        "    self.conv6 = nn.Conv2d(128,128,kernel_size=3,stride=1,padding=1,groups=2,bias=False)\n",
        "    self.bn6 = nn.BatchNorm2d(128)\n",
        "    self.conv7 = nn.Conv2d(128,256,kernel_size=1,stride=1,padding=0,bias=False)\n",
        "    self.bn7 = nn.BatchNorm2d(256)\n",
        "    \n",
        "    self.shortcut2 = nn.Sequential()\n",
        "\n",
        "    # block 3 (in_plane = 256, plane = 256, c = 2, b_w = 64, g_w =128)\n",
        "    self.conv8 = nn.Conv2d(256,128,kernel_size=1,stride=1,padding=0,bias=False)\n",
        "    self.bn8 = nn.BatchNorm2d(128)\n",
        "    self.conv9 = nn.Conv2d(128,128,kernel_size=3,stride=1,padding=1,groups=2,bias=False)\n",
        "    self.bn9 = nn.BatchNorm2d(128)\n",
        "    self.conv10 = nn.Conv2d(128,256,kernel_size=1,stride=1,padding=0,bias=False)\n",
        "    self.bn10 = nn.BatchNorm2d(256)\n",
        "    \n",
        "    self.shortcut3 = nn.Sequential()\n",
        "\n",
        "    # block 4 (in_plane = 256, plane = 512, c = 2, b_w = 128, g_w =256)\n",
        "    self.conv11 = nn.Conv2d(256,256,kernel_size=1,stride=1,padding=0,bias=False)\n",
        "    self.bn11 = nn.BatchNorm2d(256)\n",
        "    self.conv12 = nn.Conv2d(256,256,kernel_size=3,stride=2,padding=1,groups=2,bias=False)\n",
        "    self.bn12 = nn.BatchNorm2d(256)\n",
        "    self.conv13 = nn.Conv2d(256,512,kernel_size=1,stride=1,padding=0,bias=False)\n",
        "    self.bn13 = nn.BatchNorm2d(512)\n",
        "    \n",
        "    self.shortcut4 = nn.Sequential(\n",
        "        nn.Conv2d(256, 512, kernel_size=1, stride=2, bias=False),\n",
        "        nn.BatchNorm2d(512)\n",
        "        )\n",
        "    \n",
        "    # block 5 (in_plane = 512, plane = 512, c = 2, b_w = 128, g_w =256)\n",
        "    self.conv14 = nn.Conv2d(512,256,kernel_size=1,stride=1,padding=0,bias=False)\n",
        "    self.bn14 = nn.BatchNorm2d(256)\n",
        "    self.conv15 = nn.Conv2d(256,256,kernel_size=3,stride=1,padding=1,groups=2,bias=False)\n",
        "    self.bn15 = nn.BatchNorm2d(256)\n",
        "    self.conv16 = nn.Conv2d(256,512,kernel_size=1,stride=1,padding=0,bias=False)\n",
        "    self.bn16 = nn.BatchNorm2d(512)\n",
        "\n",
        "    self.shortcut5 = nn.Sequential()\n",
        "\n",
        "    # block 6 (in_plane = 512, plane = 512, c = 2, b_w = 128, g_w =256)\n",
        "    self.conv17 = nn.Conv2d(512,256,kernel_size=1,stride=1,padding=0,bias=False)\n",
        "    self.bn17 = nn.BatchNorm2d(256)\n",
        "    self.conv18 = nn.Conv2d(256,256,kernel_size=3,stride=1,padding=1,groups=2,bias=False)\n",
        "    self.bn18 = nn.BatchNorm2d(256)\n",
        "    self.conv19 = nn.Conv2d(256,512,kernel_size=1,stride=1,padding=0,bias=False)\n",
        "    self.bn19 = nn.BatchNorm2d(512)\n",
        "\n",
        "    self.shortcut6 = nn.Sequential()\n",
        "\n",
        "    # block 7 (in_plane = 512 plane = 1024, c = 2, b_w = 256, g_w =512)\n",
        "    self.conv20 = nn.Conv2d(512,512,kernel_size=1,stride=1,padding=0,bias=False)\n",
        "    self.bn20 = nn.BatchNorm2d(512)\n",
        "    self.conv21 = nn.Conv2d(512,512,kernel_size=3,stride=2,padding=1,groups=2,bias=False)\n",
        "    self.bn21 = nn.BatchNorm2d(512)\n",
        "    self.conv22 = nn.Conv2d(512,1024,kernel_size=1,stride=1,padding=0,bias=False)\n",
        "    self.bn22 = nn.BatchNorm2d(1024)\n",
        "    \n",
        "    self.shortcut7 = nn.Sequential(\n",
        "        nn.Conv2d(512, 1024, kernel_size=1, stride=2, bias=False),\n",
        "        nn.BatchNorm2d(1024)\n",
        "        )\n",
        "    \n",
        "    # block 8 (in_plane = 1024, plane = 1024, c = 2, b_w = 256, g_w = 512)\n",
        "    self.conv23 = nn.Conv2d(1024,512,kernel_size=1,stride=1,padding=0,bias=False)\n",
        "    self.bn23 = nn.BatchNorm2d(512)\n",
        "    self.conv24 = nn.Conv2d(512,512,kernel_size=3,stride=1,padding=1,groups=2,bias=False)\n",
        "    self.bn24 = nn.BatchNorm2d(512)\n",
        "    self.conv25 = nn.Conv2d(512,1024,kernel_size=1,stride=1,padding=0,bias=False)\n",
        "    self.bn25 = nn.BatchNorm2d(1024)\n",
        "\n",
        "    self.shortcut8 = nn.Sequential()\n",
        "\n",
        "    # block 9 (in_plane = 1024, plane = 1024, c = 2, b_w = 256, g_w = 512)\n",
        "    self.conv26 = nn.Conv2d(1024,512,kernel_size=1,stride=1,padding=0,bias=False)\n",
        "    self.bn26 = nn.BatchNorm2d(512)\n",
        "    self.conv27 = nn.Conv2d(512,512,kernel_size=3,stride=1,padding=1,groups=2,bias=False)\n",
        "    self.bn27 = nn.BatchNorm2d(512)\n",
        "    self.conv28 = nn.Conv2d(512,1024,kernel_size=1,stride=1,padding=0,bias=False)\n",
        "    self.bn28 = nn.BatchNorm2d(1024)\n",
        "\n",
        "    self.shortcut9 = nn.Sequential()\n",
        "\n",
        "\n",
        "    self.linear = nn.Linear(1024, num_classes)  \n",
        "\n",
        "    \n",
        "  def forward(self,x) :\n",
        "    out = F.relu(self.bn1(self.conv1(x)))\n",
        "    # block 1\n",
        "    input = out\n",
        "    out = F.relu(self.bn2(self.conv2(out)))\n",
        "    out = F.relu(self.bn3(self.conv3(out)))\n",
        "    out = self.bn4(self.conv4(out))\n",
        "    out += self.shortcut1(input)\n",
        "    out = F.relu(out)      \n",
        "    # block 2\n",
        "    input = out\n",
        "    out = F.relu(self.bn5(self.conv5(out)))\n",
        "    out = F.relu(self.bn6(self.conv6(out)))\n",
        "    out = self.bn7(self.conv7(out))\n",
        "    out += self.shortcut2(input)\n",
        "    out = F.relu(out)   \n",
        "    # block 3\n",
        "    input = out\n",
        "    out = F.relu(self.bn8(self.conv8(out)))\n",
        "    out = F.relu(self.bn9(self.conv9(out)))\n",
        "    out = self.bn10(self.conv10(out))\n",
        "    out += self.shortcut3(input)\n",
        "    out = F.relu(out)  \n",
        "    # block 4\n",
        "    input = out\n",
        "    out = F.relu(self.bn11(self.conv11(out)))\n",
        "    out = F.relu(self.bn12(self.conv12(out)))\n",
        "    out = self.bn13(self.conv13(out))\n",
        "    out += self.shortcut4(input)\n",
        "    out = F.relu(out)  \n",
        "    # block 5\n",
        "    input = out\n",
        "    out = F.relu(self.bn14(self.conv14(out)))\n",
        "    out = F.relu(self.bn15(self.conv15(out)))\n",
        "    out = self.bn16(self.conv16(out))\n",
        "    out += self.shortcut5(input)\n",
        "    out = F.relu(out)\n",
        "    # block 6\n",
        "    input = out\n",
        "    out = F.relu(self.bn17(self.conv17(out)))\n",
        "    out = F.relu(self.bn18(self.conv18(out)))\n",
        "    out = self.bn19(self.conv19(out))\n",
        "    out += self.shortcut6(input)\n",
        "    out = F.relu(out)    \n",
        "    # block 7\n",
        "    input = out\n",
        "    out = F.relu(self.bn20(self.conv20(out)))\n",
        "    out = F.relu(self.bn21(self.conv21(out)))\n",
        "    out = self.bn22(self.conv22(out))\n",
        "    out += self.shortcut7(input)\n",
        "    out = F.relu(out)    \n",
        "    # block 8\n",
        "    input = out\n",
        "    out = F.relu(self.bn23(self.conv23(out)))\n",
        "    out = F.relu(self.bn24(self.conv24(out)))\n",
        "    out = self.bn25(self.conv25(out))\n",
        "    out += self.shortcut8(input)\n",
        "    out = F.relu(out)    \n",
        "    # block 9\n",
        "    input = out\n",
        "    out = F.relu(self.bn26(self.conv26(out)))\n",
        "    out = F.relu(self.bn27(self.conv27(out)))\n",
        "    out = self.bn28(self.conv28(out))\n",
        "    out += self.shortcut9(input)\n",
        "    out = F.relu(out)          \n",
        "    \n",
        "    out = F.avg_pool2d(out, 8)\n",
        "    out = out.view(out.size(0), -1)\n",
        "    out = self.linear(out)\n",
        "    return out"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1CZ-QS4ILXu"
      },
      "source": [
        "#criterion,optimizer\n",
        "net = ResNeXt()\n",
        "net = net.to(device)\n",
        "\n",
        "learning_rate = 0.1\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0001)\n",
        "\n",
        "#scheduler\n",
        "def adjust_learning_rate(optimizer, epoch):\n",
        "    lr = learning_rate\n",
        "    if epoch >= 80:\n",
        "        lr /= 10\n",
        "    if epoch >= 120:\n",
        "        lr /= 10\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyaLTFavIToT"
      },
      "source": [
        "# train, test function\n",
        "def train(epoch):\n",
        "    print('\\n[ Train epoch: %d ]' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, prediction = outputs.max(1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += prediction.eq(labels).sum().item()\n",
        "        \n",
        "        if batch_idx % 100 == 0:\n",
        "            print('\\nCurrent batch:', str(batch_idx))\n",
        "            print('Current train accuracy:', str(prediction.eq(labels).sum().item() / labels.size(0)))\n",
        "            print('Current train average loss:', loss.item() / labels.size(0))\n",
        "\n",
        "    print('\\nTrain accuarcy:', 100. * correct / total)\n",
        "    print('Train average loss:', train_loss / total)\n",
        "\n",
        "\n",
        "def test(epoch):\n",
        "    print('\\n[ Test epoch: %d ]' % epoch)\n",
        "    net.eval()\n",
        "    loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, (images, labels) in enumerate(test_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        total += labels.size(0)\n",
        "\n",
        "        outputs = net(images)\n",
        "        loss += criterion(outputs, labels).item()\n",
        "\n",
        "        _, prediction = outputs.max(1)\n",
        "        correct += prediction.eq(labels).sum().item()\n",
        "\n",
        "    print('\\nTest accuarcy:', 100. * correct / total)\n",
        "    print('Test average loss:', loss / total)\n",
        "\n",
        "    state = {\n",
        "        'net': net.state_dict()\n",
        "    }\n",
        "\n",
        "    file_name = 'ResNeXt29_1x64d.pt'\n",
        "    if not os.path.isdir('checkpoint'):\n",
        "        os.mkdir('checkpoint')\n",
        "    torch.save(state, './checkpoint/' + file_name)\n",
        "    print('Model Saved')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 342
        },
        "id": "Hj0TL8gdMqHr",
        "outputId": "21338a42-6235-4974-b449-e3e51e5cc719"
      },
      "source": [
        "writer = SummaryWriter()\n",
        "for epoch in range(0, 300):\n",
        "    adjust_learning_rate(optimizer, epoch)\n",
        "    train(epoch)\n",
        "    test(epoch)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-e1acb0307124>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0madjust_learning_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-0f5281b386bb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3LYcZiVMtZY"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}