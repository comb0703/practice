{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df287647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "from matplotlib.image import imread\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c84d1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print(\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12fe5d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#dataset\n",
    "transformer = transforms.Compose([transforms.Resize((32, 32)),\n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                 ])\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data',\n",
    "                                        train=True,\n",
    "                                        download=True,\n",
    "                                        transform=transformer\n",
    ")\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data',\n",
    "                                       train=False,\n",
    "                                       download=True,\n",
    "                                       transform=transformer\n",
    "\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                          batch_size=32,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                         batch_size=16,\n",
    "                                         shuffle=False,\n",
    "                                         num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f2126ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    \"\"\"\n",
    "    This function is taken from the original tf repo.\n",
    "    It ensures that all layers have a channel number that is divisible by 8\n",
    "    It can be seen here:\n",
    "    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
    "    :param v:\n",
    "    :param divisor:\n",
    "    :param min_value:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "\n",
    "class h_sigmoid(nn.Module):\n",
    "    def __init__(self, inplace=True):\n",
    "        super(h_sigmoid, self).__init__()\n",
    "        self.relu = nn.ReLU6(inplace=inplace)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.relu(x + 3) / 6\n",
    "\n",
    "\n",
    "class h_swish(nn.Module):\n",
    "    def __init__(self, inplace=True):\n",
    "        super(h_swish, self).__init__()\n",
    "        self.sigmoid = h_sigmoid(inplace=inplace)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.sigmoid(x)\n",
    "\n",
    "\n",
    "class SELayer(nn.Module):\n",
    "    def __init__(self, channel, reduction=4):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "                nn.Linear(channel, _make_divisible(channel // reduction, 8)),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Linear(_make_divisible(channel // reduction, 8), channel),\n",
    "                h_sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y\n",
    "\n",
    "\n",
    "def conv_3x3_bn(inp, oup, stride):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        h_swish()\n",
    "    )\n",
    "\n",
    "\n",
    "def conv_1x1_bn(inp, oup):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        h_swish()\n",
    "    )\n",
    "\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, inp, hidden_dim, oup, kernel_size, stride, use_se, use_hs):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        assert stride in [1, 2]\n",
    "\n",
    "        self.identity = stride == 1 and inp == oup\n",
    "\n",
    "        if inp == hidden_dim:\n",
    "            self.conv = nn.Sequential(\n",
    "                # dw\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, kernel_size, stride, (kernel_size - 1) // 2, groups=hidden_dim, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                h_swish() if use_hs else nn.ReLU(inplace=True),\n",
    "                # Squeeze-and-Excite\n",
    "                SELayer(hidden_dim) if use_se else nn.Identity(),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "        else:\n",
    "            self.conv = nn.Sequential(\n",
    "                # pw\n",
    "                nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                h_swish() if use_hs else nn.ReLU(inplace=True),\n",
    "                # dw\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, kernel_size, stride, (kernel_size - 1) // 2, groups=hidden_dim, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                # Squeeze-and-Excite\n",
    "                SELayer(hidden_dim) if use_se else nn.Identity(),\n",
    "                h_swish() if use_hs else nn.ReLU(inplace=True),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.identity:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "\n",
    "\n",
    "class MobileNetV3(nn.Module):\n",
    "    def __init__(self, cfgs, mode, num_classes=10, width_mult=1.):\n",
    "        super(MobileNetV3, self).__init__()\n",
    "        # setting of inverted residual blocks\n",
    "        self.cfgs = cfgs\n",
    "        assert mode in ['large', 'small']\n",
    "\n",
    "        # building first layer\n",
    "        input_channel = _make_divisible(16 * width_mult, 8)\n",
    "        layers = [conv_3x3_bn(3, input_channel, 2)]\n",
    "        # building inverted residual blocks\n",
    "        block = InvertedResidual\n",
    "        for k, t, c, use_se, use_hs, s in self.cfgs:\n",
    "            output_channel = _make_divisible(c * width_mult, 8)\n",
    "            exp_size = _make_divisible(input_channel * t, 8)\n",
    "            layers.append(block(input_channel, exp_size, output_channel, k, s, use_se, use_hs))\n",
    "            input_channel = output_channel\n",
    "        self.features = nn.Sequential(*layers)\n",
    "        # building last several layers\n",
    "        self.conv = conv_1x1_bn(input_channel, exp_size)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        output_channel = {'large': 1280, 'small': 1024}\n",
    "        output_channel = _make_divisible(output_channel[mode] * width_mult, 8) if width_mult > 1.0 else output_channel[mode]\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(exp_size, output_channel),\n",
    "            h_swish(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(output_channel, num_classes),\n",
    "        )\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.conv(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "\n",
    "def mobilenetv3_large(**kwargs):\n",
    "    \"\"\"\n",
    "    Constructs a MobileNetV3-Large model\n",
    "    \"\"\"\n",
    "    cfgs = [\n",
    "        # k, t, c, SE, HS, s \n",
    "        [3,   1,  16, 0, 0, 1],\n",
    "        [3,   4,  24, 0, 0, 2],\n",
    "        [3,   3,  24, 0, 0, 1],\n",
    "        [5,   3,  40, 1, 0, 2],\n",
    "        [5,   3,  40, 1, 0, 1],\n",
    "        [5,   3,  40, 1, 0, 1],\n",
    "        [3,   6,  80, 0, 1, 2],\n",
    "        [3, 2.5,  80, 0, 1, 1],\n",
    "        [3, 2.3,  80, 0, 1, 1],\n",
    "        [3, 2.3,  80, 0, 1, 1],\n",
    "        [3,   6, 112, 1, 1, 1],\n",
    "        [3,   6, 112, 1, 1, 1],\n",
    "        [5,   6, 160, 1, 1, 2],\n",
    "        [5,   6, 160, 1, 1, 1],\n",
    "        [5,   6, 160, 1, 1, 1]\n",
    "    ]\n",
    "    return MobileNetV3(cfgs, mode='large', **kwargs)\n",
    "\n",
    "\n",
    "def mobilenetv3_small(**kwargs):\n",
    "    \"\"\"\n",
    "    Constructs a MobileNetV3-Small model\n",
    "    \"\"\"\n",
    "    cfgs = [\n",
    "        # k, t, c, SE, HS, s \n",
    "        [3,    1,  16, 1, 0, 2],\n",
    "        [3,  4.5,  24, 0, 0, 2],\n",
    "        [3, 3.67,  24, 0, 0, 1],\n",
    "        [5,    4,  40, 1, 1, 2],\n",
    "        [5,    6,  40, 1, 1, 1],\n",
    "        [5,    6,  40, 1, 1, 1],\n",
    "        [5,    3,  48, 1, 1, 1],\n",
    "        [5,    3,  48, 1, 1, 1],\n",
    "        [5,    6,  96, 1, 1, 2],\n",
    "        [5,    6,  96, 1, 1, 1],\n",
    "        [5,    6,  96, 1, 1, 1],\n",
    "    ]\n",
    "\n",
    "    return MobileNetV3(cfgs, mode='small', **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb34fb96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7de6b1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_accuracy = [] \n",
    "test_losses = []\n",
    "test_accuracy = []\n",
    "\n",
    "def train(epoch):\n",
    "    print('\\n[ Train epoch: %d ]' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, prediction = outputs.max(1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += prediction.eq(labels).sum().item()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('\\nCurrent batch:', str(batch_idx))\n",
    "            print('Current train accuracy:', str(prediction.eq(labels).sum().item() / labels.size(0)))\n",
    "            print('Current train average loss:', loss.item() / labels.size(0))\n",
    "\n",
    "            train_losses.append(loss.item() / labels.size(0))\n",
    "            train_accuracy.append(prediction.eq(labels).sum().item() / labels.size(0))\n",
    "            \n",
    "    print('\\nTrain accuarcy:', 100. * correct / total)\n",
    "    print('Train average loss:', train_loss / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35f8b005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    print('\\n[ Test epoch: %d ]' % epoch)\n",
    "    net.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(test_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        total += labels.size(0)\n",
    "\n",
    "        outputs = net(images)\n",
    "        loss += criterion(outputs, labels).item()\n",
    "\n",
    "        _, prediction = outputs.max(1)\n",
    "        correct += prediction.eq(labels).sum().item()\n",
    "\n",
    "    print('\\nTest accuarcy:', correct / total)\n",
    "    print('Test average loss:', loss / total)\n",
    "    test_losses.append(loss / total)\n",
    "    test_accuracy.append(correct / total)\n",
    "\n",
    "    state = {\n",
    "        'net': net.state_dict()\n",
    "    }\n",
    "\n",
    "    file_name = 'CNN_depthwise.pt'\n",
    "    if not os.path.isdir('checkpoint'):\n",
    "        os.mkdir('checkpoint')\n",
    "    torch.save(state, './checkpoint/' + file_name)\n",
    "    print('Model Saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64280d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = mobilenetv3_small()\n",
    "net = net.to(device)\n",
    "\n",
    "learning_rate = 0.1\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "395b3e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "105c4198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.528106 M\n"
     ]
    }
   ],
   "source": [
    "print(count_parameters(net)/1000000,str('M'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70ec5038",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    lr = learning_rate\n",
    "    #if epoch >= 50:\n",
    "    if epoch >= 50:\n",
    "        lr /= 10\n",
    "    #if epoch >= 100:\n",
    "    if epoch >= 100:\n",
    "        lr /= 10\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ce3bdec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ Train epoch: 0 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.0\n",
      "Current train average loss: 0.07208652794361115\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.28125\n",
      "Current train average loss: 0.0602208748459816\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.06217340752482414\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.06836426258087158\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.06282458454370499\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.07178477197885513\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.0640471875667572\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.28125\n",
      "Current train average loss: 0.0623350515961647\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.21875\n",
      "Current train average loss: 0.06503565609455109\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.06396731734275818\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.06610272079706192\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.0573132187128067\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.06422408670186996\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.125\n",
      "Current train average loss: 0.07006615400314331\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.21875\n",
      "Current train average loss: 0.06923636049032211\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.21875\n",
      "Current train average loss: 0.06531056761741638\n",
      "\n",
      "Train accuarcy: 22.448\n",
      "Train average loss: 0.06524090174198151\n",
      "\n",
      "[ Test epoch: 0 ]\n",
      "\n",
      "Test accuarcy: 0.2568\n",
      "Test average loss: 0.12390248423814773\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 66.43950915336609\n",
      "\n",
      "[ Train epoch: 1 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.058354802429676056\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.05880573391914368\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.06086722016334534\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.09375\n",
      "Current train average loss: 0.06457027792930603\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.07292021811008453\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.07102920860052109\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.125\n",
      "Current train average loss: 0.07007426768541336\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.06534062325954437\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.06801749765872955\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.0639650821685791\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.06729152798652649\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.06468550860881805\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.28125\n",
      "Current train average loss: 0.06625749915838242\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.0694689154624939\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.0679427906870842\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.06758581846952438\n",
      "\n",
      "Train accuarcy: 21.546\n",
      "Train average loss: 0.06511546087026596\n",
      "\n",
      "[ Test epoch: 1 ]\n",
      "\n",
      "Test accuarcy: 0.182\n",
      "Test average loss: 0.13257277505397796\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 134.73504972457886\n",
      "\n",
      "[ Train epoch: 2 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.06422224640846252\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.05733156576752663\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.06425599008798599\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.0625\n",
      "Current train average loss: 0.0740903839468956\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.06863639503717422\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.06912486255168915\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.21875\n",
      "Current train average loss: 0.06853616237640381\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.07441778481006622\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.07039704918861389\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.06881850957870483\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.06988154351711273\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.07073939591646194\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.07107459008693695\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.07007837295532227\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.125\n",
      "Current train average loss: 0.07347127050161362\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.125\n",
      "Current train average loss: 0.06990928947925568\n",
      "\n",
      "Train accuarcy: 14.964\n",
      "Train average loss: 0.07011738840818404\n",
      "\n",
      "[ Test epoch: 2 ]\n",
      "\n",
      "Test accuarcy: 0.1386\n",
      "Test average loss: 0.1541619656801224\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 201.68361043930054\n",
      "\n",
      "[ Train epoch: 3 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.09375\n",
      "Current train average loss: 0.06759689003229141\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.09375\n",
      "Current train average loss: 0.07162895053625107\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.0625\n",
      "Current train average loss: 0.07326684147119522\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.125\n",
      "Current train average loss: 0.07284525036811829\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.125\n",
      "Current train average loss: 0.07091891765594482\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.125\n",
      "Current train average loss: 0.07156898081302643\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.06862260401248932\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.07141490280628204\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.09375\n",
      "Current train average loss: 0.07249724119901657\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.06788899749517441\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.09375\n",
      "Current train average loss: 0.07082974910736084\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.0707029327750206\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.07062052190303802\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.07057218998670578\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.21875\n",
      "Current train average loss: 0.06855665892362595\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.07123075425624847\n",
      "\n",
      "Train accuarcy: 13.706\n",
      "Train average loss: 0.07122744582176209\n",
      "\n",
      "[ Test epoch: 3 ]\n",
      "\n",
      "Test accuarcy: 0.1449\n",
      "Test average loss: 0.14171454969644545\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 270.38043761253357\n",
      "\n",
      "[ Train epoch: 4 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.0625\n",
      "Current train average loss: 0.07566104084253311\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.0625\n",
      "Current train average loss: 0.07277323305606842\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.0625\n",
      "Current train average loss: 0.07175326347351074\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.125\n",
      "Current train average loss: 0.07373975217342377\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.125\n",
      "Current train average loss: 0.07139857858419418\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.125\n",
      "Current train average loss: 0.0710654929280281\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.21875\n",
      "Current train average loss: 0.06821916997432709\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.07276532799005508\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.05951695889234543\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.21875\n",
      "Current train average loss: 0.07487468421459198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.06712637841701508\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.0721074715256691\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.09375\n",
      "Current train average loss: 0.07237937301397324\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.125\n",
      "Current train average loss: 0.06812755018472672\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.125\n",
      "Current train average loss: 0.07187482714653015\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.06527450680732727\n",
      "\n",
      "Train accuarcy: 16.29\n",
      "Train average loss: 0.06960506879091263\n",
      "\n",
      "[ Test epoch: 4 ]\n",
      "\n",
      "Test accuarcy: 0.1736\n",
      "Test average loss: 0.13568388534784318\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 338.4782466888428\n",
      "\n",
      "[ Train epoch: 5 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.06836743652820587\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.09375\n",
      "Current train average loss: 0.07363151013851166\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.06585299223661423\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.09375\n",
      "Current train average loss: 0.07031916081905365\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.07070937007665634\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.06565435230731964\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.21875\n",
      "Current train average loss: 0.06661167740821838\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.06932520866394043\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.06886611133813858\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.06585122644901276\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.06479573994874954\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.0625\n",
      "Current train average loss: 0.07170137763023376\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.07531127333641052\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.0625\n",
      "Current train average loss: 0.06975341588258743\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.06308911740779877\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.21875\n",
      "Current train average loss: 0.06598658859729767\n",
      "\n",
      "Train accuarcy: 18.776\n",
      "Train average loss: 0.06735001605272294\n",
      "\n",
      "[ Test epoch: 5 ]\n",
      "\n",
      "Test accuarcy: 0.2013\n",
      "Test average loss: 0.13562150511741639\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 405.9716901779175\n",
      "\n",
      "[ Train epoch: 6 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.21875\n",
      "Current train average loss: 0.06765437871217728\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.06581170856952667\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.06514604389667511\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.06646458804607391\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.06105923652648926\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.125\n",
      "Current train average loss: 0.07202953845262527\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.06364991515874863\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.07525388896465302\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.125\n",
      "Current train average loss: 0.07144442200660706\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.06296383589506149\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.07162798196077347\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.125\n",
      "Current train average loss: 0.07050296664237976\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.21875\n",
      "Current train average loss: 0.0660066157579422\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.06688480079174042\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.07060809433460236\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.09375\n",
      "Current train average loss: 0.07511429488658905\n",
      "\n",
      "Train accuarcy: 20.872\n",
      "Train average loss: 0.06657872237920762\n",
      "\n",
      "[ Test epoch: 6 ]\n",
      "\n",
      "Test accuarcy: 0.1603\n",
      "Test average loss: 0.14152721619606018\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 475.5919404029846\n",
      "\n",
      "[ Train epoch: 7 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.125\n",
      "Current train average loss: 0.07213891297578812\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.06967562437057495\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.06690756976604462\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.06545502692461014\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.28125\n",
      "Current train average loss: 0.06883437186479568\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.06486919522285461\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.06801579892635345\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.06635850667953491\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.28125\n",
      "Current train average loss: 0.0620526522397995\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.06827277690172195\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.125\n",
      "Current train average loss: 0.06980964541435242\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.06634169071912766\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.125\n",
      "Current train average loss: 0.06783518195152283\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.07014355808496475\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.06764988601207733\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.06504181772470474\n",
      "\n",
      "Train accuarcy: 20.602\n",
      "Train average loss: 0.0658835830283165\n",
      "\n",
      "[ Test epoch: 7 ]\n",
      "\n",
      "Test accuarcy: 0.2353\n",
      "Test average loss: 0.12746782368421555\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 543.8691532611847\n",
      "\n",
      "[ Train epoch: 8 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.21875\n",
      "Current train average loss: 0.06571801751852036\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.06390657275915146\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.125\n",
      "Current train average loss: 0.06480631977319717\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.09375\n",
      "Current train average loss: 0.07407373189926147\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.07096294313669205\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.0625\n",
      "Current train average loss: 0.07114224880933762\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.06395920366048813\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.21875\n",
      "Current train average loss: 0.0704219713807106\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.06191181391477585\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.125\n",
      "Current train average loss: 0.06920874118804932\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.061577361077070236\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.06560971587896347\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.06665433198213577\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.06560353934764862\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.059400226920843124\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.21875\n",
      "Current train average loss: 0.06639106571674347\n",
      "\n",
      "Train accuarcy: 21.694\n",
      "Train average loss: 0.06576319614887237\n",
      "\n",
      "[ Test epoch: 8 ]\n",
      "\n",
      "Test accuarcy: 0.2127\n",
      "Test average loss: 0.13096280559301376\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 611.2882330417633\n",
      "\n",
      "[ Train epoch: 9 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.06802394986152649\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.06173671409487724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.09375\n",
      "Current train average loss: 0.06763884425163269\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.21875\n",
      "Current train average loss: 0.0685599073767662\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.06338267028331757\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.125\n",
      "Current train average loss: 0.06834617257118225\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.125\n",
      "Current train average loss: 0.0645146444439888\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.058909714221954346\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.05402795597910881\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.06165853515267372\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.07000387459993362\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.06244850531220436\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.21875\n",
      "Current train average loss: 0.06370293349027634\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.06408706307411194\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.125\n",
      "Current train average loss: 0.06558986008167267\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.28125\n",
      "Current train average loss: 0.06486747413873672\n",
      "\n",
      "Train accuarcy: 23.794\n",
      "Train average loss: 0.06371983324050903\n",
      "\n",
      "[ Test epoch: 9 ]\n",
      "\n",
      "Test accuarcy: 0.1755\n",
      "Test average loss: 0.13390208053588867\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 678.294468164444\n",
      "\n",
      "[ Train epoch: 10 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.06473377346992493\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.06749849766492844\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.07194127887487411\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.21875\n",
      "Current train average loss: 0.06708624213933945\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.0670657604932785\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.0636068806052208\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.06682539731264114\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.07045359909534454\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.06876987218856812\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.06873507797718048\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.06818098574876785\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.21875\n",
      "Current train average loss: 0.07787524163722992\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.28125\n",
      "Current train average loss: 0.05951749533414841\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.21875\n",
      "Current train average loss: 0.05894414335489273\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.125\n",
      "Current train average loss: 0.0663711205124855\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.28125\n",
      "Current train average loss: 0.05644581839442253\n",
      "\n",
      "Train accuarcy: 20.31\n",
      "Train average loss: 0.06628350972652436\n",
      "\n",
      "[ Test epoch: 10 ]\n",
      "\n",
      "Test accuarcy: 0.2322\n",
      "Test average loss: 0.1340330552339554\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 745.2220287322998\n",
      "\n",
      "[ Train epoch: 11 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.21875\n",
      "Current train average loss: 0.07203550636768341\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.28125\n",
      "Current train average loss: 0.06412898004055023\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.0631655678153038\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.06252356618642807\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.06835640966892242\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.06380074471235275\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.21875\n",
      "Current train average loss: 0.05714812129735947\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.057414133101701736\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.07068385183811188\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.06243489682674408\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.125\n",
      "Current train average loss: 0.06360375136137009\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.06528522819280624\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.125\n",
      "Current train average loss: 0.06715808808803558\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.06603603065013885\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.06264463812112808\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.06418662518262863\n",
      "\n",
      "Train accuarcy: 22.174\n",
      "Train average loss: 0.06474581672668457\n",
      "\n",
      "[ Test epoch: 11 ]\n",
      "\n",
      "Test accuarcy: 0.2355\n",
      "Test average loss: 0.12766197811365126\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 811.9595556259155\n",
      "\n",
      "[ Train epoch: 12 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.0709041878581047\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.06112103536725044\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.21875\n",
      "Current train average loss: 0.07138194888830185\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.09375\n",
      "Current train average loss: 0.06910408288240433\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.0666562095284462\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.060013048350811005\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.06608794629573822\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.06207367405295372\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.06945424526929855\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.28125\n",
      "Current train average loss: 0.058697570115327835\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.125\n",
      "Current train average loss: 0.069825679063797\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.06316062808036804\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.06610811501741409\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.06603487581014633\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.21875\n",
      "Current train average loss: 0.06056975573301315\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.06787354499101639\n",
      "\n",
      "Train accuarcy: 20.862\n",
      "Train average loss: 0.06528412132024765\n",
      "\n",
      "[ Test epoch: 12 ]\n",
      "\n",
      "Test accuarcy: 0.1651\n",
      "Test average loss: 0.13489499380588532\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 878.5462553501129\n",
      "\n",
      "[ Train epoch: 13 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.07045704126358032\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.06169157847762108\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.07263635843992233\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.06536342948675156\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.06883758306503296\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.125\n",
      "Current train average loss: 0.07153148949146271\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.21875\n",
      "Current train average loss: 0.0703960657119751\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.125\n",
      "Current train average loss: 0.06799794733524323\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.125\n",
      "Current train average loss: 0.06455903500318527\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.07013736665248871\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.06054122745990753\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.06196926161646843\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.125\n",
      "Current train average loss: 0.065554678440094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.06535361707210541\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.21875\n",
      "Current train average loss: 0.0673631951212883\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.28125\n",
      "Current train average loss: 0.06884825974702835\n",
      "\n",
      "Train accuarcy: 19.272\n",
      "Train average loss: 0.06631908879041672\n",
      "\n",
      "[ Test epoch: 13 ]\n",
      "\n",
      "Test accuarcy: 0.2328\n",
      "Test average loss: 0.1290444118499756\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 947.2466571331024\n",
      "\n",
      "[ Train epoch: 14 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.06229640170931816\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.06950367242097855\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.05752946063876152\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.062258172780275345\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.21875\n",
      "Current train average loss: 0.06700603663921356\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.28125\n",
      "Current train average loss: 0.0605742484331131\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.06326936185359955\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.06268300861120224\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.06243112310767174\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.21875\n",
      "Current train average loss: 0.060455773025751114\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.07219288498163223\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.03125\n",
      "Current train average loss: 0.07167384773492813\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.28125\n",
      "Current train average loss: 0.060870636254549026\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.06564536690711975\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.06082269549369812\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.06797602027654648\n",
      "\n",
      "Train accuarcy: 23.266\n",
      "Train average loss: 0.06395597032785416\n",
      "\n",
      "[ Test epoch: 14 ]\n",
      "\n",
      "Test accuarcy: 0.2121\n",
      "Test average loss: 0.12875946661233903\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 1015.4243040084839\n",
      "\n",
      "[ Train epoch: 15 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.09375\n",
      "Current train average loss: 0.06851081550121307\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.06285823881626129\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.06800725311040878\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.0690901055932045\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.09375\n",
      "Current train average loss: 0.06904582679271698\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.28125\n",
      "Current train average loss: 0.06840144097805023\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.060905322432518005\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.05947576463222504\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.21875\n",
      "Current train average loss: 0.06224745884537697\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.21875\n",
      "Current train average loss: 0.0640219897031784\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.06434426456689835\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.06831491738557816\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.06569501012563705\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.21875\n",
      "Current train average loss: 0.06512612849473953\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.21875\n",
      "Current train average loss: 0.0653211921453476\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.28125\n",
      "Current train average loss: 0.06099535524845123\n",
      "\n",
      "Train accuarcy: 21.506\n",
      "Train average loss: 0.06506297233581543\n",
      "\n",
      "[ Test epoch: 15 ]\n",
      "\n",
      "Test accuarcy: 0.2723\n",
      "Test average loss: 0.12301046421527863\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 1082.8114798069\n",
      "\n",
      "[ Train epoch: 16 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.28125\n",
      "Current train average loss: 0.06351445615291595\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.06005874276161194\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.21875\n",
      "Current train average loss: 0.06250185519456863\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.0717555582523346\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.06138566508889198\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.057254716753959656\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.06578420102596283\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.06436232477426529\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.06770727783441544\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.06004560738801956\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.125\n",
      "Current train average loss: 0.06360217928886414\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.21875\n",
      "Current train average loss: 0.06596393138170242\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.06085992977023125\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.06090178340673447\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.05958240106701851\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.06363877654075623\n",
      "\n",
      "Train accuarcy: 25.93\n",
      "Train average loss: 0.062065837364196776\n",
      "\n",
      "[ Test epoch: 16 ]\n",
      "\n",
      "Test accuarcy: 0.2964\n",
      "Test average loss: 0.11883705170154571\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 1150.5357694625854\n",
      "\n",
      "[ Train epoch: 17 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.15625\n",
      "Current train average loss: 0.0724867582321167\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.06385579705238342\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.062280476093292236\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.05146881937980652\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.06660796701908112\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.05435110628604889\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.28125\n",
      "Current train average loss: 0.05588994547724724\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.06381416320800781\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.28125\n",
      "Current train average loss: 0.06366541981697083\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.05327555164694786\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.28125\n",
      "Current train average loss: 0.05718537047505379\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.061613768339157104\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.056463807821273804\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.052352167665958405\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.051896896213293076\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.060908395797014236\n",
      "\n",
      "Train accuarcy: 29.532\n",
      "Train average loss: 0.05918253322601318\n",
      "\n",
      "[ Test epoch: 17 ]\n",
      "\n",
      "Test accuarcy: 0.3127\n",
      "Test average loss: 0.11431234837770463\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 1218.289217710495\n",
      "\n",
      "[ Train epoch: 18 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.053352292627096176\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.052133046090602875\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.05360078811645508\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.04951988533139229\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.06622175127267838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.04696297273039818\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.049670495092868805\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.055101677775382996\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.06126423552632332\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.054593782871961594\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.28125\n",
      "Current train average loss: 0.06359589844942093\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.050635676831007004\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.04820464923977852\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04678267985582352\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.28125\n",
      "Current train average loss: 0.056998562067747116\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.048471368849277496\n",
      "\n",
      "Train accuarcy: 34.786\n",
      "Train average loss: 0.05523379741668701\n",
      "\n",
      "[ Test epoch: 18 ]\n",
      "\n",
      "Test accuarcy: 0.3599\n",
      "Test average loss: 0.11058590577840804\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 1285.6475627422333\n",
      "\n",
      "[ Train epoch: 19 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.058932382613420486\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.04648489132523537\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.051551658660173416\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.04656841233372688\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.044384729117155075\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.05155510455369949\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.28125\n",
      "Current train average loss: 0.06207875907421112\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.05351598560810089\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04686076566576958\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.04649072885513306\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.048949167132377625\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.04939243569970131\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.05378242954611778\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.050575338304042816\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.04459773004055023\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.05467584356665611\n",
      "\n",
      "Train accuarcy: 37.352\n",
      "Train average loss: 0.052947498540878296\n",
      "\n",
      "[ Test epoch: 19 ]\n",
      "\n",
      "Test accuarcy: 0.3878\n",
      "Test average loss: 0.10437163125276566\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 1353.4584922790527\n",
      "\n",
      "[ Train epoch: 20 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.05366170406341553\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.05871809646487236\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.05292346328496933\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.047388408333063126\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.03908243030309677\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.049814898520708084\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.05963122844696045\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.05378955230116844\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04982773959636688\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.04645208641886711\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04439883679151535\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.04927883297204971\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.047972433269023895\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.04447907581925392\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.05651388689875603\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.052092019468545914\n",
      "\n",
      "Train accuarcy: 39.792\n",
      "Train average loss: 0.05131411048173905\n",
      "\n",
      "[ Test epoch: 20 ]\n",
      "\n",
      "Test accuarcy: 0.4067\n",
      "Test average loss: 0.10078246218562126\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 1420.6837639808655\n",
      "\n",
      "[ Train epoch: 21 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.050600722432136536\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.04883508384227753\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04756389185786247\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.05519518256187439\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.055949967354536057\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.043799638748168945\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.28125\n",
      "Current train average loss: 0.05282265320420265\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.051900994032621384\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.04015275835990906\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.049636274576187134\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.04683244600892067\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.04700750112533569\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.05439344793558121\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.03833033889532089\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.05456222593784332\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.05123061314225197\n",
      "\n",
      "Train accuarcy: 41.57\n",
      "Train average loss: 0.049884565567970274\n",
      "\n",
      "[ Test epoch: 21 ]\n",
      "\n",
      "Test accuarcy: 0.3892\n",
      "Test average loss: 0.10724015243053436\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 1488.7119164466858\n",
      "\n",
      "[ Train epoch: 22 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.05472064018249512\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.0457611121237278\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.05648316442966461\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04411471262574196\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.05079151317477226\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.05176106095314026\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.05146416649222374\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.04811020940542221\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.053246211260557175\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.04226995259523392\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.0448182076215744\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.05920479819178581\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.04939725995063782\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.046659305691719055\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.04814844951033592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.049024924635887146\n",
      "\n",
      "Train accuarcy: 42.824\n",
      "Train average loss: 0.04910611444473267\n",
      "\n",
      "[ Test epoch: 22 ]\n",
      "\n",
      "Test accuarcy: 0.4359\n",
      "Test average loss: 0.096586608594656\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 1555.28648519516\n",
      "\n",
      "[ Train epoch: 23 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.04674829542636871\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.04710754379630089\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04118436947464943\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.28125\n",
      "Current train average loss: 0.051774490624666214\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.04878741502761841\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.21875\n",
      "Current train average loss: 0.05797532945871353\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.047626614570617676\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.04583510011434555\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.04433560371398926\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.03507227823138237\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.03853324055671692\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.04746381193399429\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.043060366064310074\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.05252572521567345\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.03804571181535721\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.04533820226788521\n",
      "\n",
      "Train accuarcy: 43.418\n",
      "Train average loss: 0.048487471208572386\n",
      "\n",
      "[ Test epoch: 23 ]\n",
      "\n",
      "Test accuarcy: 0.4366\n",
      "Test average loss: 0.09436285331249238\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 1621.747880935669\n",
      "\n",
      "[ Train epoch: 24 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.05483259633183479\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.03705192357301712\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04886441305279732\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.04161547124385834\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.04942970350384712\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.044608306139707565\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.0472167506814003\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.047601621598005295\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04514911398291588\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.04354380443692207\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.043971266597509384\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.05373339727520943\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.0582755021750927\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.050594862550497055\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.049876660108566284\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.05429912358522415\n",
      "\n",
      "Train accuarcy: 43.94\n",
      "Train average loss: 0.04836507717847824\n",
      "\n",
      "[ Test epoch: 24 ]\n",
      "\n",
      "Test accuarcy: 0.4442\n",
      "Test average loss: 0.09498990034461022\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 1689.1328032016754\n",
      "\n",
      "[ Train epoch: 25 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.04151855409145355\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.04972813278436661\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.03844514861702919\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.04606107249855995\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.04759233817458153\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.046766363084316254\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.05251385271549225\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.051690589636564255\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.05033980309963226\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.04570181295275688\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.0553923100233078\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.039311401546001434\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.042804259806871414\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.04974356293678284\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.04677511379122734\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.05872555449604988\n",
      "\n",
      "Train accuarcy: 44.2\n",
      "Train average loss: 0.04779136747121811\n",
      "\n",
      "[ Test epoch: 25 ]\n",
      "\n",
      "Test accuarcy: 0.449\n",
      "Test average loss: 0.0934846195757389\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 1757.098494052887\n",
      "\n",
      "[ Train epoch: 26 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04912329092621803\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.03885440528392792\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.04399315267801285\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.05173303186893463\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04595572501420975\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.04141603037714958\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.049845289438962936\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.04064909368753433\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.048762835562229156\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.04095124453306198\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.055238641798496246\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.046675968915224075\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.03583521395921707\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.04940640926361084\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.047036029398441315\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.05153290182352066\n",
      "\n",
      "Train accuarcy: 44.866\n",
      "Train average loss: 0.04761333359599113\n",
      "\n",
      "[ Test epoch: 26 ]\n",
      "\n",
      "Test accuarcy: 0.4307\n",
      "Test average loss: 0.09664623019695281\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 1824.6332304477692\n",
      "\n",
      "[ Train epoch: 27 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.04249731823801994\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.05473249405622482\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.041276153177022934\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04952966421842575\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.047425806522369385\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.04004070535302162\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.03882472589612007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.05066147446632385\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.28125\n",
      "Current train average loss: 0.05595816671848297\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.05237351730465889\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.04289431497454643\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.051658932119607925\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.28125\n",
      "Current train average loss: 0.05540979653596878\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.042011383920907974\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.04216398298740387\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.0549759604036808\n",
      "\n",
      "Train accuarcy: 45.06\n",
      "Train average loss: 0.04726387208104134\n",
      "\n",
      "[ Test epoch: 27 ]\n",
      "\n",
      "Test accuarcy: 0.4211\n",
      "Test average loss: 0.09866041755080224\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 1892.2446718215942\n",
      "\n",
      "[ Train epoch: 28 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.04741423949599266\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.04543524608016014\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.04411599412560463\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.05622219666838646\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.058810289949178696\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.03988193720579147\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.05248308181762695\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.05182129517197609\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.04419514909386635\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.03915318846702576\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.047267548739910126\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.04302243888378143\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.0436827652156353\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.0540601871907711\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.04587050527334213\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04908279329538345\n",
      "\n",
      "Train accuarcy: 45.49\n",
      "Train average loss: 0.04716817776441574\n",
      "\n",
      "[ Test epoch: 28 ]\n",
      "\n",
      "Test accuarcy: 0.4627\n",
      "Test average loss: 0.09176628341078759\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 1960.7221658229828\n",
      "\n",
      "[ Train epoch: 29 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.04320482909679413\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.05371233820915222\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.04589416831731796\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.04446811601519585\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.049256332218647\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.0482126921415329\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.05031711608171463\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.04639448970556259\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.059885017573833466\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.041011467576026917\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.0465274453163147\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.03965789079666138\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04182521998882294\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.0359811894595623\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.0425914004445076\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.05014423280954361\n",
      "\n",
      "Train accuarcy: 45.87\n",
      "Train average loss: 0.04684765818357468\n",
      "\n",
      "[ Test epoch: 29 ]\n",
      "\n",
      "Test accuarcy: 0.4677\n",
      "Test average loss: 0.09138114151358605\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 2028.5413143634796\n",
      "\n",
      "[ Train epoch: 30 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.04903673008084297\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.05062822625041008\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.040571510791778564\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04434517025947571\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.0395718514919281\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.05353574454784393\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.050180502235889435\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.05079950392246246\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.043867968022823334\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.042775750160217285\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.04247890040278435\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.04130290076136589\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.05083371698856354\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.041851796209812164\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.06206616759300232\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.04073496535420418\n",
      "\n",
      "Train accuarcy: 45.952\n",
      "Train average loss: 0.04671416534304619\n",
      "\n",
      "[ Test epoch: 30 ]\n",
      "\n",
      "Test accuarcy: 0.4632\n",
      "Test average loss: 0.09227621332406998\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 2097.8611640930176\n",
      "\n",
      "[ Train epoch: 31 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.037508878856897354\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.04013333469629288\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.042340751737356186\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.04767676442861557\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.043239809572696686\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.045613862574100494\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.04609476774930954\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.046299561858177185\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.04376383125782013\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.054858990013599396\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.04626072198152542\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.051060598343610764\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.21875\n",
      "Current train average loss: 0.05575649440288544\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.037071287631988525\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.04904133453965187\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04343511909246445\n",
      "\n",
      "Train accuarcy: 46.156\n",
      "Train average loss: 0.046498517475128176\n",
      "\n",
      "[ Test epoch: 31 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test accuarcy: 0.4649\n",
      "Test average loss: 0.0908116106569767\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 2165.681088209152\n",
      "\n",
      "[ Train epoch: 32 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.04182439669966698\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.049479641020298004\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.040766336023807526\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.05086735263466835\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.056966908276081085\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.051192522048950195\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.043856676667928696\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.04648594185709953\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.039328545331954956\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04641569405794144\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.04624900966882706\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.04219641163945198\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.043558262288570404\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04351593554019928\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.04356975853443146\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.04316893219947815\n",
      "\n",
      "Train accuarcy: 46.11\n",
      "Train average loss: 0.04650802180886269\n",
      "\n",
      "[ Test epoch: 32 ]\n",
      "\n",
      "Test accuarcy: 0.4667\n",
      "Test average loss: 0.09083508549332618\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 2232.9873332977295\n",
      "\n",
      "[ Train epoch: 33 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.04431861639022827\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.05300990119576454\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.03938118740916252\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.04423869773745537\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.043212395161390305\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.050073977559804916\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.04787968099117279\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.040209680795669556\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.05257069692015648\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.05021185427904129\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04488803818821907\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.05553801357746124\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.05016399547457695\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.04698284715414047\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.04957471787929535\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.04749347269535065\n",
      "\n",
      "Train accuarcy: 46.44\n",
      "Train average loss: 0.046208350297212604\n",
      "\n",
      "[ Test epoch: 33 ]\n",
      "\n",
      "Test accuarcy: 0.4569\n",
      "Test average loss: 0.09430774121284485\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 2300.4704768657684\n",
      "\n",
      "[ Train epoch: 34 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.05341234803199768\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04492109641432762\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.038815632462501526\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.06319205462932587\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.03477010503411293\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.036628976464271545\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.052461765706539154\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.0420711413025856\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.05095280706882477\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.04463992640376091\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.04722895845770836\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.050030726939439774\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.05347657576203346\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.042412497103214264\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.052146755158901215\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.03653397038578987\n",
      "\n",
      "Train accuarcy: 46.614\n",
      "Train average loss: 0.046176650693416595\n",
      "\n",
      "[ Test epoch: 34 ]\n",
      "\n",
      "Test accuarcy: 0.4825\n",
      "Test average loss: 0.09125101413726806\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 2367.9618940353394\n",
      "\n",
      "[ Train epoch: 35 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.048788417130708694\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.04401013255119324\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.04253942891955376\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.03876766189932823\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.04931987449526787\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.03983115032315254\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.04687783494591713\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.04827365651726723\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.045668475329875946\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.04367725923657417\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.05033209174871445\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04243424907326698\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.05495993420481682\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.04477085918188095\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.05802953988313675\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.03851708024740219\n",
      "\n",
      "Train accuarcy: 47.168\n",
      "Train average loss: 0.045816841012239456\n",
      "\n",
      "[ Test epoch: 35 ]\n",
      "\n",
      "Test accuarcy: 0.4753\n",
      "Test average loss: 0.09044043303728104\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 2435.338490009308\n",
      "\n",
      "[ Train epoch: 36 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.043985914438962936\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.05007101222872734\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.04714671149849892\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.062790147960186\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.28125\n",
      "Current train average loss: 0.05447935685515404\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04673701524734497\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.044498346745967865\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.05670253559947014\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.049403440207242966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.04347929358482361\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.04370561242103577\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.043597690761089325\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.050030965358018875\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04616528004407883\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.039961230009794235\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.04246905818581581\n",
      "\n",
      "Train accuarcy: 47.084\n",
      "Train average loss: 0.045817184755802154\n",
      "\n",
      "[ Test epoch: 36 ]\n",
      "\n",
      "Test accuarcy: 0.4691\n",
      "Test average loss: 0.09291451727151871\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 2502.95032954216\n",
      "\n",
      "[ Train epoch: 37 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.050107941031455994\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.049197763204574585\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.039268139749765396\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.05745619162917137\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.040058355778455734\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.03975886106491089\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.038631372153759\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.04738537222146988\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.04480055719614029\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.043019842356443405\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.0486433170735836\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.05193519592285156\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.04402885586023331\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.041917432099580765\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.05092665180563927\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.040044575929641724\n",
      "\n",
      "Train accuarcy: 47.418\n",
      "Train average loss: 0.04563654193639755\n",
      "\n",
      "[ Test epoch: 37 ]\n",
      "\n",
      "Test accuarcy: 0.4448\n",
      "Test average loss: 0.09808050744533539\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 2570.681217432022\n",
      "\n",
      "[ Train epoch: 38 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.03485538437962532\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.045551545917987823\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.21875\n",
      "Current train average loss: 0.06914599984884262\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.05249583721160889\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.04013530910015106\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.03677124157547951\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.045834239572286606\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.04176344722509384\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.04554525762796402\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.03928323835134506\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.04617893695831299\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.043099403381347656\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.055641040205955505\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.04298120364546776\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.04383349418640137\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04471155256032944\n",
      "\n",
      "Train accuarcy: 47.314\n",
      "Train average loss: 0.04555741374254227\n",
      "\n",
      "[ Test epoch: 38 ]\n",
      "\n",
      "Test accuarcy: 0.4952\n",
      "Test average loss: 0.08710062218904495\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 2638.9332168102264\n",
      "\n",
      "[ Train epoch: 39 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.04244884476065636\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.04070689529180527\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.04879448935389519\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.03213971480727196\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.04485028237104416\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.0450335256755352\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.0334642231464386\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.040742404758930206\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04704836755990982\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.05116511136293411\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.055109623819589615\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.04566477611660957\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.04146396741271019\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.04296960309147835\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.04032445698976517\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04513748735189438\n",
      "\n",
      "Train accuarcy: 47.788\n",
      "Train average loss: 0.04529184577226639\n",
      "\n",
      "[ Test epoch: 39 ]\n",
      "\n",
      "Test accuarcy: 0.4781\n",
      "Test average loss: 0.09104491245746613\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 2707.3373970985413\n",
      "\n",
      "[ Train epoch: 40 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.035087715834379196\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.049465540796518326\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.048077430576086044\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04834068566560745\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.03995738923549652\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.04372681304812431\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.04325835779309273\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.0385766476392746\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.043408725410699844\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.03743618354201317\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04957924783229828\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.048401206731796265\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.05212068185210228\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.043850310146808624\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.04058900475502014\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.0451500378549099\n",
      "\n",
      "Train accuarcy: 47.932\n",
      "Train average loss: 0.04516335074782372\n",
      "\n",
      "[ Test epoch: 40 ]\n",
      "\n",
      "Test accuarcy: 0.4917\n",
      "Test average loss: 0.08805066287517548\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 2775.1992666721344\n",
      "\n",
      "[ Train epoch: 41 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.04332229867577553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.04190026968717575\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.03493072837591171\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.03274054825305939\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.046130307018756866\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.05173334851861\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.04660367965698242\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.04806313291192055\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.031096259132027626\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.04332224279642105\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.04062390327453613\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.042993005365133286\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.04488974064588547\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.04532521963119507\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.0444340705871582\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.04416944459080696\n",
      "\n",
      "Train accuarcy: 47.746\n",
      "Train average loss: 0.04525930741548538\n",
      "\n",
      "[ Test epoch: 41 ]\n",
      "\n",
      "Test accuarcy: 0.4834\n",
      "Test average loss: 0.08940421407222748\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 2842.0857627391815\n",
      "\n",
      "[ Train epoch: 42 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.0454181507229805\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04945670813322067\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.05057412385940552\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.04313059523701668\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04030316323041916\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.05742949992418289\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.04942543804645538\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.043122440576553345\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.054966770112514496\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.05358165130019188\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.039809755980968475\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.033653806895017624\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.04197891056537628\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.05965573713183403\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.0551627092063427\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.03914984315633774\n",
      "\n",
      "Train accuarcy: 47.918\n",
      "Train average loss: 0.04525256314754486\n",
      "\n",
      "[ Test epoch: 42 ]\n",
      "\n",
      "Test accuarcy: 0.4915\n",
      "Test average loss: 0.08750993156433105\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 2908.946150779724\n",
      "\n",
      "[ Train epoch: 43 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.03469095006585121\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.03372998908162117\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.039663225412368774\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.044802434742450714\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.04539668187499046\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.04513996094465256\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04442182555794716\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.050791483372449875\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.04534907266497612\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.03477475047111511\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.03828270360827446\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.04276997968554497\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.05265308916568756\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.041273083537817\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.04443962126970291\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.057916030287742615\n",
      "\n",
      "Train accuarcy: 48.392\n",
      "Train average loss: 0.04482205313324928\n",
      "\n",
      "[ Test epoch: 43 ]\n",
      "\n",
      "Test accuarcy: 0.4825\n",
      "Test average loss: 0.08975360081195831\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 2975.5650928020477\n",
      "\n",
      "[ Train epoch: 44 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.04682976379990578\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.037537552416324615\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.045563239604234695\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.047575123608112335\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.052132949233055115\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.05344608426094055\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.28125\n",
      "Current train average loss: 0.055409885942935944\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.04919373616576195\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.04568149894475937\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.03846907243132591\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.042209330946207047\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.04959990829229355\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.044202350080013275\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.0450739786028862\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.041829489171504974\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.04833736643195152\n",
      "\n",
      "Train accuarcy: 48.31\n",
      "Train average loss: 0.04490201731801033\n",
      "\n",
      "[ Test epoch: 44 ]\n",
      "\n",
      "Test accuarcy: 0.4912\n",
      "Test average loss: 0.08849841821193695\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 3042.862046480179\n",
      "\n",
      "[ Train epoch: 45 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.03975814953446388\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.043706558644771576\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.04461735486984253\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.047211870551109314\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.0460418276488781\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.04373155161738396\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.03854874521493912\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.04293440654873848\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.04667524993419647\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.03729284927248955\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04992038756608963\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.037592265754938126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.05446360260248184\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.052681952714920044\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.04015224054455757\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.03557133302092552\n",
      "\n",
      "Train accuarcy: 48.28\n",
      "Train average loss: 0.044772526836395266\n",
      "\n",
      "[ Test epoch: 45 ]\n",
      "\n",
      "Test accuarcy: 0.4917\n",
      "Test average loss: 0.08884748394489288\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 3109.939755678177\n",
      "\n",
      "[ Train epoch: 46 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.05101427808403969\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.038659628480672836\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.052717652171850204\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04485068842768669\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.04039165377616882\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.046137962490320206\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.048059627413749695\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.03733553737401962\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.05442696064710617\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.04260654002428055\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.04849407076835632\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.041250139474868774\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.28125\n",
      "Current train average loss: 0.055811915546655655\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.059660620987415314\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.042880311608314514\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.03496893495321274\n",
      "\n",
      "Train accuarcy: 48.394\n",
      "Train average loss: 0.04462921391248703\n",
      "\n",
      "[ Test epoch: 46 ]\n",
      "\n",
      "Test accuarcy: 0.4638\n",
      "Test average loss: 0.09200837745070457\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 3176.9534196853638\n",
      "\n",
      "[ Train epoch: 47 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.0367233045399189\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.05007654055953026\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.0501985065639019\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.05715253949165344\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.05799933895468712\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.04326971620321274\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04883464053273201\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.05254003405570984\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.04223276674747467\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.03698403015732765\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.053551916033029556\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.04737314209342003\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.053378209471702576\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.03576007857918739\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.050898708403110504\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.05445827543735504\n",
      "\n",
      "Train accuarcy: 48.728\n",
      "Train average loss: 0.044667569246292116\n",
      "\n",
      "[ Test epoch: 47 ]\n",
      "\n",
      "Test accuarcy: 0.4874\n",
      "Test average loss: 0.08817088047862053\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 3243.820981025696\n",
      "\n",
      "[ Train epoch: 48 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.04434282332658768\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.04462352395057678\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.0455753430724144\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.03665334731340408\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.0491691529750824\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.04322531074285507\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.0431288406252861\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.03753587603569031\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.03509402275085449\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04327724128961563\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.04544605687260628\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.04284384846687317\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04804794490337372\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.03882719948887825\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04930536076426506\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.050209224224090576\n",
      "\n",
      "Train accuarcy: 48.93\n",
      "Train average loss: 0.044546157444715496\n",
      "\n",
      "[ Test epoch: 48 ]\n",
      "\n",
      "Test accuarcy: 0.4866\n",
      "Test average loss: 0.0888313627243042\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 3310.7019884586334\n",
      "\n",
      "[ Train epoch: 49 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.04532867297530174\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.04437519237399101\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.0368029810488224\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.04455391317605972\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.04450719803571701\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.04292672127485275\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.05005066096782684\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.05400201305747032\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.040764447301626205\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.25\n",
      "Current train average loss: 0.06059101223945618\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.036951787769794464\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.04132138192653656\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.04748661816120148\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.03439662978053093\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.03633992373943329\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.04764699935913086\n",
      "\n",
      "Train accuarcy: 48.628\n",
      "Train average loss: 0.044634137961864474\n",
      "\n",
      "[ Test epoch: 49 ]\n",
      "\n",
      "Test accuarcy: 0.4827\n",
      "Test average loss: 0.0891009244441986\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 3377.556044816971\n",
      "\n",
      "[ Train epoch: 50 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.28125\n",
      "Current train average loss: 0.05497986450791359\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.03410838916897774\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.041638340801000595\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04980616271495819\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.04164524003863335\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.04601123929023743\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.039612896740436554\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.04284582659602165\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.0490248017013073\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04913119971752167\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.041418664157390594\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.042002804577350616\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.036046240478754044\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.047485362738370895\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.03942098468542099\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.03011108934879303\n",
      "\n",
      "Train accuarcy: 49.186\n",
      "Train average loss: 0.044372434377670286\n",
      "\n",
      "[ Test epoch: 50 ]\n",
      "\n",
      "Test accuarcy: 0.4857\n",
      "Test average loss: 0.08975161768198013\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 3444.3159470558167\n",
      "\n",
      "[ Train epoch: 51 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.0444154292345047\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.04477078840136528\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.045633718371391296\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.04009849950671196\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.0449543222784996\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.05094972252845764\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.04384886845946312\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.03919732943177223\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.04081291705369949\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.041622571647167206\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.036726098507642746\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.04756208136677742\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.05197269842028618\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04617874324321747\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.04177040234208107\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.043241169303655624\n",
      "\n",
      "Train accuarcy: 48.968\n",
      "Train average loss: 0.04429897069811821\n",
      "\n",
      "[ Test epoch: 51 ]\n",
      "\n",
      "Test accuarcy: 0.4752\n",
      "Test average loss: 0.08997555112242699\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 3511.590505361557\n",
      "\n",
      "[ Train epoch: 52 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.03985006362199783\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.03962311893701553\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04920482635498047\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.04340093955397606\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.04047052934765816\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.048524048179388046\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.03998579829931259\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.04983077943325043\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.04758381098508835\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.05026071518659592\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.03877170383930206\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04228891432285309\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.05061321705579758\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.04453471675515175\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.05603590980172157\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.03747536614537239\n",
      "\n",
      "Train accuarcy: 48.988\n",
      "Train average loss: 0.04437242970228195\n",
      "\n",
      "[ Test epoch: 52 ]\n",
      "\n",
      "Test accuarcy: 0.5073\n",
      "Test average loss: 0.08674636506438255\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 3578.1754055023193\n",
      "\n",
      "[ Train epoch: 53 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.049796976149082184\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.04005696624517441\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.04042186960577965\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.04160234332084656\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.04100559279322624\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.04387638717889786\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.04254539683461189\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.04423154890537262\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04240952432155609\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.027040403336286545\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.038628146052360535\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.051065463572740555\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.035306379199028015\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.053143683820962906\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.047982439398765564\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.05614793673157692\n",
      "\n",
      "Train accuarcy: 49.318\n",
      "Train average loss: 0.0441098825609684\n",
      "\n",
      "[ Test epoch: 53 ]\n",
      "\n",
      "Test accuarcy: 0.4979\n",
      "Test average loss: 0.0871881987452507\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 3644.74897480011\n",
      "\n",
      "[ Train epoch: 54 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.04821779951453209\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.04219447076320648\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04212780296802521\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.04845413193106651\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.05532757192850113\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.04854585602879524\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04154433310031891\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.28125\n",
      "Current train average loss: 0.0545194111764431\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.04218218848109245\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.04643314331769943\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.0491533987224102\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04798014089465141\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.04446178674697876\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.28125\n",
      "Current train average loss: 0.05879582092165947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.05455286428332329\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.056298960000276566\n",
      "\n",
      "Train accuarcy: 49.084\n",
      "Train average loss: 0.044324912201166154\n",
      "\n",
      "[ Test epoch: 54 ]\n",
      "\n",
      "Test accuarcy: 0.5054\n",
      "Test average loss: 0.08597188556194306\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 3711.7404062747955\n",
      "\n",
      "[ Train epoch: 55 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.038505226373672485\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.04516730457544327\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.04010695964097977\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.04099242761731148\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.06226646527647972\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.048679761588573456\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.04662414640188217\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04425373300909996\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.04606061801314354\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.03901434689760208\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.03964810445904732\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04302629455924034\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.038735952228307724\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.04860858619213104\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.03468115255236626\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.05039796233177185\n",
      "\n",
      "Train accuarcy: 49.284\n",
      "Train average loss: 0.04417677865624428\n",
      "\n",
      "[ Test epoch: 55 ]\n",
      "\n",
      "Test accuarcy: 0.4744\n",
      "Test average loss: 0.09139843313694\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 3778.5615541934967\n",
      "\n",
      "[ Train epoch: 56 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.04030242934823036\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.04030543938279152\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.044923022389411926\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.047456592321395874\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.03812922537326813\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.05305195227265358\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.04319982975721359\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.03405548632144928\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.04519280791282654\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.040682315826416016\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.03844969719648361\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.04863649234175682\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.02551219053566456\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.03891504928469658\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.041950542479753494\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.048137787729501724\n",
      "\n",
      "Train accuarcy: 49.428\n",
      "Train average loss: 0.044077882034778595\n",
      "\n",
      "[ Test epoch: 56 ]\n",
      "\n",
      "Test accuarcy: 0.48\n",
      "Test average loss: 0.08824009585380554\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 3845.1383616924286\n",
      "\n",
      "[ Train epoch: 57 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.04069133847951889\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.04010885953903198\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.04023835062980652\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.04707862064242363\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.04406711459159851\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.040366146713495255\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.036721792072057724\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.04543425887823105\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.0554182231426239\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.03887667879462242\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.03741515055298805\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.04488588497042656\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.03842957690358162\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.04314923658967018\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.047885600477457047\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04354235157370567\n",
      "\n",
      "Train accuarcy: 49.452\n",
      "Train average loss: 0.04410374081254005\n",
      "\n",
      "[ Test epoch: 57 ]\n",
      "\n",
      "Test accuarcy: 0.4918\n",
      "Test average loss: 0.08836487730145455\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 3911.729803085327\n",
      "\n",
      "[ Train epoch: 58 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.04776664823293686\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.05883326008915901\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.04360407590866089\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04144259914755821\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.04978149011731148\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.04518115893006325\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.28125\n",
      "Current train average loss: 0.04958111047744751\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.05351618304848671\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.04263390228152275\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.045154958963394165\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.0392431765794754\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.04559626802802086\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.050182465463876724\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.047647874802351\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.05833635851740837\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.04771076515316963\n",
      "\n",
      "Train accuarcy: 49.304\n",
      "Train average loss: 0.04398235825300217\n",
      "\n",
      "[ Test epoch: 58 ]\n",
      "\n",
      "Test accuarcy: 0.5047\n",
      "Test average loss: 0.08572498915195464\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 3978.3809418678284\n",
      "\n",
      "[ Train epoch: 59 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04323652386665344\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.05754366144537926\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.036956243216991425\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.05134105682373047\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.051374610513448715\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.04949178919196129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.04036008194088936\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.04123712703585625\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.049810875207185745\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.047518663108348846\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.05283522233366966\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.05449096858501434\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.04512111842632294\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.05212279409170151\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.039927322417497635\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.055685240775346756\n",
      "\n",
      "Train accuarcy: 49.51\n",
      "Train average loss: 0.04404209363460541\n",
      "\n",
      "[ Test epoch: 59 ]\n",
      "\n",
      "Test accuarcy: 0.5007\n",
      "Test average loss: 0.08731367018818856\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 4047.6049489974976\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(0, 60):\n",
    "    #adjust_learning_rate(optimizer, epoch)\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    print('\\nTime elapsed:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "602da3ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train_l = pd.DataFrame(train_losses, columns = ['train_losses'])\n",
    "df_train_l.plot(color = \"#ff0000\")\n",
    "plt.plot(df_train_l, marker = '*', color = 'r')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b328a078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train_a = pd.DataFrame(train_accuracy, columns = ['train_accuracy'])\n",
    "df_train_a.plot(color = \"#ff1111\")\n",
    "plt.plot(df_train_a, marker = '.', color = 'b')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "175ed897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test_l = pd.DataFrame(test_losses, columns = ['test_losses'])\n",
    "df_test_l.plot(color = \"#ff0000\")\n",
    "plt.plot(df_test_l, marker = '*', color = 'r')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a3c47ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test_a = pd.DataFrame(test_accuracy, columns = ['test_accuracy'])\n",
    "df_test_a.plot(color = \"#ff0000\")\n",
    "plt.plot(df_test_a, marker = '*', color = 'r')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "539f58b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting update\n",
      "  Downloading update-0.0.1-py2.py3-none-any.whl (2.9 kB)\n",
      "Collecting style==1.1.0\n",
      "  Downloading style-1.1.0-py2.py3-none-any.whl (6.4 kB)\n",
      "Installing collected packages: style, update\n",
      "Successfully installed style-1.1.0 update-0.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0ddf23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ptflops in c:\\programdata\\anaconda3\\lib\\site-packages (0.6.6)\n",
      "Requirement already satisfied: torch in c:\\programdata\\anaconda3\\lib\\site-packages (from ptflops) (1.9.0)\n",
      "Requirement already satisfied: typing_extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from torch->ptflops) (3.7.4.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ptflops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a4aacf19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/sovrasov/flops-counter.pytorch.gitNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone -q https://github.com/sovrasov/flops-counter.pytorch.git 'C:\\Users\\admin\\AppData\\Local\\Temp\\pip-req-build-8x3qg9jw'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Cloning https://github.com/sovrasov/flops-counter.pytorch.git to c:\\users\\admin\\appdata\\local\\temp\\pip-req-build-8x3qg9jw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  ERROR: Error [WinError 2]      while executing command git clone -q https://github.com/sovrasov/flops-counter.pytorch.git 'C:\\Users\\admin\\AppData\\Local\\Temp\\pip-req-build-8x3qg9jw'\n",
      "ERROR: Cannot find command 'git' - do you have 'git' installed and in your PATH?\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade git+https://github.com/sovrasov/flops-counter.pytorch.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d0fb0185",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-21-711b33cc299d>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-21-711b33cc299d>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    pip install ptflops\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Multiply-Accumulate\n",
    "pip install ptflops\n",
    "pip install --upgrade git+https://github.com/sovrasov/flops-counter.pytorch.git\n",
    "import torchvision.models as models\n",
    "import torch\n",
    "from ptflops import get_model_complexity_info\n",
    "\n",
    "with torch.cuda.device(0):\n",
    "    macs, params = get_model_complexity_info(net, (3, 224, 224), as_strings=True,\n",
    "                                           print_per_layer_stat=True, verbose=True)\n",
    "    print('{:<30}  {:<8}'.format('Computational complexity: ', macs))\n",
    "    print('{:<30}  {:<8}'.format('Number of parameters: ', params))\n",
    "    print('= ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aac8b518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aad046c",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_paramete"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
