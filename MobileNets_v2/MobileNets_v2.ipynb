{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df287647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "from matplotlib.image import imread\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c84d1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print(\"error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12fe5d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "#dataset\n",
    "transformer = transforms.Compose([transforms.Resize((32, 32)),\n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                                 ])\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data',\n",
    "                                        train=True,\n",
    "                                        download=True,\n",
    "                                        transform=transformer\n",
    ")\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data',\n",
    "                                       train=False,\n",
    "                                       download=True,\n",
    "                                       transform=transformer\n",
    "\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                          batch_size=32,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                         batch_size=16,\n",
    "                                         shuffle=False,\n",
    "                                         num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f2126ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_planes, out_planes, expansion, stride):\n",
    "        super(Block, self).__init__()\n",
    "        self.stride = stride\n",
    "\n",
    "        planes = expansion * in_planes\n",
    "        # channel expansion\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        # depthwise convolution\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, groups=planes, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride == 1:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "                nn.BatchNorm2d(out_planes),\n",
    "                nn.ReLU(inplace=True),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu6(self.bn1(self.conv1(x)))\n",
    "        out = F.relu6(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out = out + self.shortcut(x) if self.stride==1 else out\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class MobileNetV2(nn.Module):\n",
    "    cfg = [(1,  16, 1, 1),\n",
    "           (6,  24, 2, 1),  \n",
    "           (6,  32, 3, 2),\n",
    "           (6,  64, 4, 2),\n",
    "           (6,  96, 3, 1),\n",
    "           (6, 160, 3, 2),\n",
    "           (6, 320, 1, 1)]\n",
    "\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.layers = self._make_layers(in_planes=32)\n",
    "        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(1280)\n",
    "        self.linear = nn.Linear(1280, num_classes)\n",
    "\n",
    "    def _make_layers(self, in_planes):\n",
    "        layers = []\n",
    "        for expansion, out_planes, num_blocks, stride in self.cfg:\n",
    "            strides = [stride] + [1]*(num_blocks-1)\n",
    "            for stride in strides:\n",
    "                layers.append(Block(in_planes, out_planes, expansion, stride))\n",
    "                in_planes = out_planes\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.layers(out)\n",
    "        out = F.relu(self.bn2(self.conv2(out)))\n",
    "        out = F.avg_pool2d(out, 4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb34fb96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7de6b1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_accuracy = [] \n",
    "test_losses = []\n",
    "test_accuracy = []\n",
    "\n",
    "def train(epoch):\n",
    "    print('\\n[ Train epoch: %d ]' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = net(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, prediction = outputs.max(1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += prediction.eq(labels).sum().item()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('\\nCurrent batch:', str(batch_idx))\n",
    "            print('Current train accuracy:', str(prediction.eq(labels).sum().item() / labels.size(0)))\n",
    "            print('Current train average loss:', loss.item() / labels.size(0))\n",
    "\n",
    "            train_losses.append(loss.item() / labels.size(0))\n",
    "            train_accuracy.append(prediction.eq(labels).sum().item() / labels.size(0))\n",
    "            \n",
    "    print('\\nTrain accuarcy:', 100. * correct / total)\n",
    "    print('Train average loss:', train_loss / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "35f8b005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    print('\\n[ Test epoch: %d ]' % epoch)\n",
    "    net.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(test_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        total += labels.size(0)\n",
    "\n",
    "        outputs = net(images)\n",
    "        loss += criterion(outputs, labels).item()\n",
    "\n",
    "        _, prediction = outputs.max(1)\n",
    "        correct += prediction.eq(labels).sum().item()\n",
    "\n",
    "    print('\\nTest accuarcy:', correct / total)\n",
    "    print('Test average loss:', loss / total)\n",
    "    test_losses.append(loss / total)\n",
    "    test_accuracy.append(correct / total)\n",
    "\n",
    "    state = {\n",
    "        'net': net.state_dict()\n",
    "    }\n",
    "\n",
    "    file_name = 'CNN_depthwise.pt'\n",
    "    if not os.path.isdir('checkpoint'):\n",
    "        os.mkdir('checkpoint')\n",
    "    torch.save(state, './checkpoint/' + file_name)\n",
    "    print('Model Saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64280d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MobileNetV2()\n",
    "net = net.to(device)\n",
    "\n",
    "learning_rate = 0.1\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "395b3e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_parameters\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "105c4198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.38305 M\n"
     ]
    }
   ],
   "source": [
    "print(count_parameters(net)/1000000,str('M'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70ec5038",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    lr = learning_rate\n",
    "    #if epoch >= 50:\n",
    "    if epoch >= 50:\n",
    "        lr /= 10\n",
    "    #if epoch >= 100:\n",
    "    if epoch >= 100:\n",
    "        lr /= 10\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ce3bdec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ Train epoch: 0 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.09375\n",
      "Current train average loss: 0.07246356457471848\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.21875\n",
      "Current train average loss: 0.06429380178451538\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.06656244397163391\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.059534817934036255\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.375\n",
      "Current train average loss: 0.06313076615333557\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.05738672614097595\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.052859872579574585\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.21875\n",
      "Current train average loss: 0.05456184223294258\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.1875\n",
      "Current train average loss: 0.06434153020381927\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.05062391608953476\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.048953019082546234\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.055046774446964264\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.04987788200378418\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.3125\n",
      "Current train average loss: 0.06042974069714546\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.05196806415915489\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.05905293673276901\n",
      "\n",
      "Train accuarcy: 30.984\n",
      "Train average loss: 0.05818815983295441\n",
      "\n",
      "[ Test epoch: 0 ]\n",
      "\n",
      "Test accuarcy: 0.4283\n",
      "Test average loss: 0.09521695860028268\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 320.27090311050415\n",
      "\n",
      "[ Train epoch: 1 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.40625\n",
      "Current train average loss: 0.0452725924551487\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.21875\n",
      "Current train average loss: 0.05267135053873062\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.048687517642974854\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.041384726762771606\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.040483783930540085\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.28125\n",
      "Current train average loss: 0.048134420067071915\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.04694351553916931\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.03415660187602043\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.03365570679306984\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.04577445238828659\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.04752387851476669\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.034436408430337906\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.03604065254330635\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.038057565689086914\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.042191505432128906\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.34375\n",
      "Current train average loss: 0.050613757222890854\n",
      "\n",
      "Train accuarcy: 48.172\n",
      "Train average loss: 0.044366478021144864\n",
      "\n",
      "[ Test epoch: 1 ]\n",
      "\n",
      "Test accuarcy: 0.525\n",
      "Test average loss: 0.08141919502615928\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 649.1680479049683\n",
      "\n",
      "[ Train epoch: 2 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.037432074546813965\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.04711581766605377\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.03552563488483429\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.03797420859336853\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.028864432126283646\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.04084280878305435\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.047998201102018356\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.029050320386886597\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.035697806626558304\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.03564665466547012\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.46875\n",
      "Current train average loss: 0.04892069101333618\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.0342070534825325\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.038333725184202194\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.03257765993475914\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.020446324720978737\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.035957321524620056\n",
      "\n",
      "Train accuarcy: 57.792\n",
      "Train average loss: 0.036661867364645\n",
      "\n",
      "[ Test epoch: 2 ]\n",
      "\n",
      "Test accuarcy: 0.6127\n",
      "Test average loss: 0.06761000037193299\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 981.387567281723\n",
      "\n",
      "[ Train epoch: 3 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.03914017602801323\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.02976708486676216\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.03281509503722191\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.04087090492248535\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.03600924089550972\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.035047635436058044\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.02937939018011093\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.02429509535431862\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.5\n",
      "Current train average loss: 0.03550436347723007\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.04311387985944748\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.026292696595191956\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.024914534762501717\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.028200574219226837\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.02971656247973442\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.022125480696558952\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.0335550494492054\n",
      "\n",
      "Train accuarcy: 64.012\n",
      "Train average loss: 0.03175659255564213\n",
      "\n",
      "[ Test epoch: 3 ]\n",
      "\n",
      "Test accuarcy: 0.6477\n",
      "Test average loss: 0.0633417423248291\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 1318.4109210968018\n",
      "\n",
      "[ Train epoch: 4 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.02496821992099285\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.025924496352672577\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.025652695447206497\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.03712054342031479\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.028298979625105858\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.037529051303863525\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.04975268617272377\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.018836159259080887\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.033560559153556824\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.02527083456516266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.027918148785829544\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.02947615459561348\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.03156246617436409\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.03460431098937988\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.03928821161389351\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.03949515148997307\n",
      "\n",
      "Train accuarcy: 67.688\n",
      "Train average loss: 0.028678283632993698\n",
      "\n",
      "[ Test epoch: 4 ]\n",
      "\n",
      "Test accuarcy: 0.6386\n",
      "Test average loss: 0.06486516731381416\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 1657.9725835323334\n",
      "\n",
      "[ Train epoch: 5 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.02741919457912445\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.028378061950206757\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.03631529584527016\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.022639211267232895\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.02239236608147621\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.029219625517725945\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.0292697474360466\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.01805969327688217\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.026477476581931114\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.02702713944017887\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.0225271787494421\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.030155625194311142\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.04112058877944946\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.029835987836122513\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.015472405590116978\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.019280187785625458\n",
      "\n",
      "Train accuarcy: 70.72\n",
      "Train average loss: 0.026545705726742745\n",
      "\n",
      "[ Test epoch: 5 ]\n",
      "\n",
      "Test accuarcy: 0.6972\n",
      "Test average loss: 0.05480172864496708\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 1995.2165224552155\n",
      "\n",
      "[ Train epoch: 6 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.02932238020002842\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.02472110278904438\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.01563793607056141\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.03176609426736832\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.023499619215726852\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.023832613602280617\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.0193452388048172\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.0205856803804636\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.010680672712624073\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.02477198839187622\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.03133052960038185\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.023742498829960823\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.030212100595235825\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.03918744996190071\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.020647190511226654\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.023040547966957092\n",
      "\n",
      "Train accuarcy: 72.428\n",
      "Train average loss: 0.025195674433112145\n",
      "\n",
      "[ Test epoch: 6 ]\n",
      "\n",
      "Test accuarcy: 0.7153\n",
      "Test average loss: 0.05261227979809046\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 2333.726532459259\n",
      "\n",
      "[ Train epoch: 7 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.0271667018532753\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.025020631030201912\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.025110691785812378\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.029141956940293312\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.02252837084233761\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.0221543088555336\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.025425612926483154\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.022984465584158897\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.019792817533016205\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.01940496452152729\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.02753155305981636\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.022701701149344444\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.026344774290919304\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.025380317121744156\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.02485045976936817\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.021033598110079765\n",
      "\n",
      "Train accuarcy: 73.538\n",
      "Train average loss: 0.02400827918857336\n",
      "\n",
      "[ Test epoch: 7 ]\n",
      "\n",
      "Test accuarcy: 0.7072\n",
      "Test average loss: 0.05376581134200096\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 2673.061831474304\n",
      "\n",
      "[ Train epoch: 8 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.022747615352272987\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.013213226571679115\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.02766767144203186\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.020735785365104675\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.01306343637406826\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.014435757882893085\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.033152010291814804\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.01968439109623432\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.021024947986006737\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.01969803124666214\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.012271006591618061\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.018527870997786522\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.024565424770116806\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.02173999510705471\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.026251722127199173\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.03319459781050682\n",
      "\n",
      "Train accuarcy: 74.58\n",
      "Train average loss: 0.02335077617406845\n",
      "\n",
      "[ Test epoch: 8 ]\n",
      "\n",
      "Test accuarcy: 0.7295\n",
      "Test average loss: 0.04907211278378963\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 3014.05513048172\n",
      "\n",
      "[ Train epoch: 9 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.011965405195951462\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.01725786365568638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.02159729227423668\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.020983632653951645\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.017193568870425224\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.01851748488843441\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.02300015650689602\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.014289558865129948\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.013986392877995968\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.015168457292020321\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.015267983078956604\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.030420348048210144\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.018705233931541443\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.025993119925260544\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.02567317523062229\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.025855330750346184\n",
      "\n",
      "Train accuarcy: 75.144\n",
      "Train average loss: 0.022818748928010463\n",
      "\n",
      "[ Test epoch: 9 ]\n",
      "\n",
      "Test accuarcy: 0.7513\n",
      "Test average loss: 0.04522277421951294\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 3357.5800433158875\n",
      "\n",
      "[ Train epoch: 10 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.017194073647260666\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.02028355747461319\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.03981930762529373\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.01650559902191162\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.028191298246383667\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.021466132253408432\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.015574772842228413\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.015909047797322273\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.03178975731134415\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.018704785034060478\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.020695829764008522\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.024996193125844002\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.016507688909769058\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.01645614393055439\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.019740384072065353\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.02258175052702427\n",
      "\n",
      "Train accuarcy: 75.54\n",
      "Train average loss: 0.02245391012251377\n",
      "\n",
      "[ Test epoch: 10 ]\n",
      "\n",
      "Test accuarcy: 0.73\n",
      "Test average loss: 0.05065553157478571\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 3697.2761569023132\n",
      "\n",
      "[ Train epoch: 11 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.016086768358945847\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.021314438432455063\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.016728263348340988\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.0225275419652462\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.018924003466963768\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.023424435406923294\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.018244706094264984\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.017707262188196182\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.02652069926261902\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.027820073068141937\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.030638253316283226\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.01769491657614708\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.026924030855298042\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.023797981441020966\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.02740730531513691\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.01679813116788864\n",
      "\n",
      "Train accuarcy: 76.248\n",
      "Train average loss: 0.02183264583081007\n",
      "\n",
      "[ Test epoch: 11 ]\n",
      "\n",
      "Test accuarcy: 0.7476\n",
      "Test average loss: 0.0466306527890265\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 4037.1237387657166\n",
      "\n",
      "[ Train epoch: 12 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.9375\n",
      "Current train average loss: 0.011847502551972866\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.022342097014188766\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.03371443971991539\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.017759719863533974\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.02151050791144371\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.02090289816260338\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.013603804633021355\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.024810340255498886\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.015090291388332844\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.02022944577038288\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.02487649768590927\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.021408719941973686\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.016292085871100426\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.01758378930389881\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.022727396339178085\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.03245222568511963\n",
      "\n",
      "Train accuarcy: 76.246\n",
      "Train average loss: 0.021714312254488468\n",
      "\n",
      "[ Test epoch: 12 ]\n",
      "\n",
      "Test accuarcy: 0.7511\n",
      "Test average loss: 0.04485756512582302\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 4377.285743713379\n",
      "\n",
      "[ Train epoch: 13 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.01643841154873371\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.021975571289658546\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.022582879289984703\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.015246604569256306\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.0151006318628788\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.033641885966062546\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.0314936526119709\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.022313859313726425\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.03893975913524628\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.011394312605261803\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.014310932718217373\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.02256762608885765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.022734099999070168\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.4375\n",
      "Current train average loss: 0.03910413756966591\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.020452002063393593\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.0177475456148386\n",
      "\n",
      "Train accuarcy: 76.822\n",
      "Train average loss: 0.021274765633940696\n",
      "\n",
      "[ Test epoch: 13 ]\n",
      "\n",
      "Test accuarcy: 0.7401\n",
      "Test average loss: 0.04786335359215736\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 4715.9629826545715\n",
      "\n",
      "[ Train epoch: 14 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.020993338897824287\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.0175450649112463\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.017861461266875267\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.018697090446949005\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.027503272518515587\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.014234083704650402\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.024076852947473526\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.011837078258395195\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.016177192330360413\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.012886439450085163\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.03597855940461159\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.011503232643008232\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.018865657970309258\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.017727971076965332\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.017968518659472466\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.024374568834900856\n",
      "\n",
      "Train accuarcy: 76.882\n",
      "Train average loss: 0.021150135126709938\n",
      "\n",
      "[ Test epoch: 14 ]\n",
      "\n",
      "Test accuarcy: 0.754\n",
      "Test average loss: 0.04476099390760064\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 5053.7618932724\n",
      "\n",
      "[ Train epoch: 15 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.010705862194299698\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.022983012720942497\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.031178509816527367\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.01686008647084236\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.017769746482372284\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.015522702597081661\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.01812754198908806\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.029390932992100716\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.011737730354070663\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.017697729170322418\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.01789472997188568\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.0116523876786232\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.02232992649078369\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.024907777085900307\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.02409088797867298\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.02397545799612999\n",
      "\n",
      "Train accuarcy: 76.932\n",
      "Train average loss: 0.02116039531826973\n",
      "\n",
      "[ Test epoch: 15 ]\n",
      "\n",
      "Test accuarcy: 0.7539\n",
      "Test average loss: 0.04556436648666859\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 5389.602832555771\n",
      "\n",
      "[ Train epoch: 16 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.02504628896713257\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.014649813994765282\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.027177346870303154\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.02153317630290985\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.01844307780265808\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 1.0\n",
      "Current train average loss: 0.004517749417573214\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.016965042799711227\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.015658380463719368\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.026379354298114777\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.041561372578144073\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.02470543421804905\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.021413344889879227\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.01699223183095455\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.028088150545954704\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.0283321775496006\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.020196573808789253\n",
      "\n",
      "Train accuarcy: 77.42\n",
      "Train average loss: 0.020732830040454866\n",
      "\n",
      "[ Test epoch: 16 ]\n",
      "\n",
      "Test accuarcy: 0.7495\n",
      "Test average loss: 0.04572695183455944\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 5726.749449253082\n",
      "\n",
      "[ Train epoch: 17 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.01620456948876381\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.01117774099111557\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.022012144327163696\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.024196330457925797\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.02133527584373951\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.02961832471191883\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.015658406540751457\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.026853889226913452\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.028739193454384804\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.02604524977505207\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.02638290263712406\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.016845233738422394\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.025159385055303574\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.02009628899395466\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.020451035350561142\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.020695760846138\n",
      "\n",
      "Train accuarcy: 77.492\n",
      "Train average loss: 0.02059306675285101\n",
      "\n",
      "[ Test epoch: 17 ]\n",
      "\n",
      "Test accuarcy: 0.7607\n",
      "Test average loss: 0.04387727198153734\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 6066.50377869606\n",
      "\n",
      "[ Train epoch: 18 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.013831417076289654\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.010394142009317875\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.015032706782221794\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.030458934605121613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.02548684924840927\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.02263820916414261\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.017024608328938484\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.02217836119234562\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.021099604666233063\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.018768833950161934\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.014616744592785835\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.02149929665029049\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.020687900483608246\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.023440057411789894\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.01580500416457653\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.021403932943940163\n",
      "\n",
      "Train accuarcy: 78.022\n",
      "Train average loss: 0.02025463509231806\n",
      "\n",
      "[ Test epoch: 18 ]\n",
      "\n",
      "Test accuarcy: 0.7473\n",
      "Test average loss: 0.046501871716976166\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 6405.173872947693\n",
      "\n",
      "[ Train epoch: 19 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.017712587490677834\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.014158658683300018\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.015594408847391605\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.022370364516973495\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.019953399896621704\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.01598283275961876\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.01749068684875965\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.018143264576792717\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.017877474427223206\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.02884032391011715\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.02669440396130085\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.023090142756700516\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.014747550711035728\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.021237937733530998\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.019858255982398987\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.019329573959112167\n",
      "\n",
      "Train accuarcy: 77.98\n",
      "Train average loss: 0.020353953531980516\n",
      "\n",
      "[ Test epoch: 19 ]\n",
      "\n",
      "Test accuarcy: 0.7565\n",
      "Test average loss: 0.04536939149908721\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 6742.619892835617\n",
      "\n",
      "[ Train epoch: 20 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.024094490334391594\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.03205990046262741\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.013669702224433422\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.01187015138566494\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.014461714774370193\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.02850198745727539\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.025851376354694366\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.02018665336072445\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.01825127750635147\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.02482438087463379\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.02450474537909031\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.021253079175949097\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.02176661416888237\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.015930701047182083\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.53125\n",
      "Current train average loss: 0.03408088535070419\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.025742964819073677\n",
      "\n",
      "Train accuarcy: 78.256\n",
      "Train average loss: 0.02004700004696846\n",
      "\n",
      "[ Test epoch: 20 ]\n",
      "\n",
      "Test accuarcy: 0.7633\n",
      "Test average loss: 0.043290716506540775\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 7079.550792694092\n",
      "\n",
      "[ Train epoch: 21 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.014944368042051792\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.019333265721797943\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.015326275490224361\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.014354351907968521\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.022128945216536522\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.02434481680393219\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.021914377808570862\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.019207410514354706\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.01813148707151413\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.02249934896826744\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.020302221179008484\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.0127791166305542\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.017044497653841972\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.015280907042324543\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.025124119594693184\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.03100965917110443\n",
      "\n",
      "Train accuarcy: 78.008\n",
      "Train average loss: 0.020093570415079594\n",
      "\n",
      "[ Test epoch: 21 ]\n",
      "\n",
      "Test accuarcy: 0.7397\n",
      "Test average loss: 0.048796095272898674\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 7416.802420139313\n",
      "\n",
      "[ Train epoch: 22 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.014717417769134045\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.02118884027004242\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.9375\n",
      "Current train average loss: 0.009323028847575188\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.020489241927862167\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.019425421953201294\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.020625516772270203\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.011962179094552994\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.01962713710963726\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.026921408250927925\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.01856881193816662\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.011683502234518528\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.018129196017980576\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.022032324224710464\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.022890059277415276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.0168655663728714\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.008436333388090134\n",
      "\n",
      "Train accuarcy: 78.536\n",
      "Train average loss: 0.019763694635033607\n",
      "\n",
      "[ Test epoch: 22 ]\n",
      "\n",
      "Test accuarcy: 0.7513\n",
      "Test average loss: 0.047947910277545455\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 7754.852644443512\n",
      "\n",
      "[ Train epoch: 23 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.017269907519221306\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.02384224161505699\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.02163076028227806\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.01912263035774231\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.016970112919807434\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.014211772941052914\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.01664011739194393\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.02664957568049431\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.012223444879055023\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.018245086073875427\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.019262628629803658\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.02096370980143547\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.018349459394812584\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.01982133463025093\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.013787366449832916\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.018946152180433273\n",
      "\n",
      "Train accuarcy: 78.55\n",
      "Train average loss: 0.019875560949146748\n",
      "\n",
      "[ Test epoch: 23 ]\n",
      "\n",
      "Test accuarcy: 0.7398\n",
      "Test average loss: 0.04920726927816868\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 8091.823141813278\n",
      "\n",
      "[ Train epoch: 24 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.023135583847761154\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.02632509358227253\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.03751000016927719\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.017059270292520523\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.019712159410119057\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.020626982674002647\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.01321015227586031\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.01845032162964344\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.03572229668498039\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.019577879458665848\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.019519571214914322\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.01950734294950962\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.01986607164144516\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.019383426755666733\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.020955203101038933\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.016543680801987648\n",
      "\n",
      "Train accuarcy: 78.796\n",
      "Train average loss: 0.01958175979793072\n",
      "\n",
      "[ Test epoch: 24 ]\n",
      "\n",
      "Test accuarcy: 0.7792\n",
      "Test average loss: 0.04036663481965661\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 8432.171415090561\n",
      "\n",
      "[ Train epoch: 25 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.018077747896313667\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.02587965317070484\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.02443002723157406\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.0183812715113163\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.014675251208245754\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.96875\n",
      "Current train average loss: 0.008840908296406269\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.02146225795149803\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.9375\n",
      "Current train average loss: 0.018014997243881226\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.016712183132767677\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.016919376328587532\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.012623923830688\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.014354182407259941\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.015437748283147812\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.018944039940834045\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.023117398843169212\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.011571246199309826\n",
      "\n",
      "Train accuarcy: 78.888\n",
      "Train average loss: 0.01938990530192852\n",
      "\n",
      "[ Test epoch: 25 ]\n",
      "\n",
      "Test accuarcy: 0.7707\n",
      "Test average loss: 0.041946746722608806\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 8770.133109092712\n",
      "\n",
      "[ Train epoch: 26 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.019326824694871902\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.01885605789721012\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.03396967425942421\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.02393433265388012\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.021456526592373848\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.019107764586806297\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.01132217887789011\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.02584187313914299\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.023716798052191734\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.028698761016130447\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.020670415833592415\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.031505975872278214\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.015317569486796856\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.01562628336250782\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.01421069074422121\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.017768966034054756\n",
      "\n",
      "Train accuarcy: 78.928\n",
      "Train average loss: 0.019437137548625468\n",
      "\n",
      "[ Test epoch: 26 ]\n",
      "\n",
      "Test accuarcy: 0.7486\n",
      "Test average loss: 0.04682023323625326\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 9110.101830482483\n",
      "\n",
      "[ Train epoch: 27 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.021095123142004013\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.024638401344418526\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.01932215318083763\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.015881536528468132\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.017788032069802284\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.020932629704475403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.018948616459965706\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.02182461880147457\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.01422402635216713\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.01857219822704792\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.014318670146167278\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.01852625049650669\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.020509842783212662\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.015563501045107841\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.01011735014617443\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.01278128381818533\n",
      "\n",
      "Train accuarcy: 78.858\n",
      "Train average loss: 0.019327454691827298\n",
      "\n",
      "[ Test epoch: 27 ]\n",
      "\n",
      "Test accuarcy: 0.753\n",
      "Test average loss: 0.04628834527730942\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 9450.653174638748\n",
      "\n",
      "[ Train epoch: 28 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.01814122684299946\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.023428166285157204\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.02736297994852066\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.012947628274559975\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.013809185475111008\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.016837412491440773\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.0331948846578598\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.019406944513320923\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.02115040272474289\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.02707373909652233\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.9375\n",
      "Current train average loss: 0.012400041334331036\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.00927927065640688\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.04005545377731323\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.015980316326022148\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.027521690353751183\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.02274087816476822\n",
      "\n",
      "Train accuarcy: 79.23\n",
      "Train average loss: 0.019018761256933213\n",
      "\n",
      "[ Test epoch: 28 ]\n",
      "\n",
      "Test accuarcy: 0.7768\n",
      "Test average loss: 0.04143097150027752\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 9791.708690166473\n",
      "\n",
      "[ Train epoch: 29 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.014649552293121815\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.015344372019171715\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.018617428839206696\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.013960868120193481\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.016497841104865074\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.022867301478981972\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.02261808142066002\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.025983747094869614\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.02635468915104866\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.020619124174118042\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.01344248466193676\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.01562785543501377\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.028738735243678093\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.019093269482254982\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.01667427457869053\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.019951028749346733\n",
      "\n",
      "Train accuarcy: 79.304\n",
      "Train average loss: 0.018979002123773098\n",
      "\n",
      "[ Test epoch: 29 ]\n",
      "\n",
      "Test accuarcy: 0.748\n",
      "Test average loss: 0.047025795201957224\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 10131.565531492233\n",
      "\n",
      "[ Train epoch: 30 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.015693938359618187\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.018824072554707527\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.015820186585187912\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.9375\n",
      "Current train average loss: 0.007371079176664352\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.013223481364548206\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.01971035823225975\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.014969161711633205\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.014919542707502842\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.032102931290864944\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.02509118989109993\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.02738972008228302\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.014837334863841534\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.023709068074822426\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.02265770547091961\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.018280651420354843\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.013585258275270462\n",
      "\n",
      "Train accuarcy: 79.464\n",
      "Train average loss: 0.018813172384500504\n",
      "\n",
      "[ Test epoch: 30 ]\n",
      "\n",
      "Test accuarcy: 0.7296\n",
      "Test average loss: 0.05225348133146763\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 10469.710578918457\n",
      "\n",
      "[ Train epoch: 31 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.013921045698225498\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.017281848937273026\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.025381434708833694\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.022650564089417458\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.02031274512410164\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.019937895238399506\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.013945057056844234\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.024761158972978592\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.020657267421483994\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.023915313184261322\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.022931823506951332\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.02599792182445526\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.02173633500933647\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.02305033802986145\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.022335490211844444\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.02361142821609974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train accuarcy: 79.058\n",
      "Train average loss: 0.0192905977922678\n",
      "\n",
      "[ Test epoch: 31 ]\n",
      "\n",
      "Test accuarcy: 0.7719\n",
      "Test average loss: 0.04267314650639892\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 10806.322543859482\n",
      "\n",
      "[ Train epoch: 32 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.015128012746572495\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.015579025261104107\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.02110058255493641\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.02128758653998375\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.9375\n",
      "Current train average loss: 0.009955155663192272\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.01670835167169571\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.027308152988553047\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.01566747948527336\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.012498552910983562\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.017367467284202576\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.01825692318379879\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.015969349071383476\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.023160286247730255\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.008490088395774364\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.014616877771914005\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.006911371368914843\n",
      "\n",
      "Train accuarcy: 79.506\n",
      "Train average loss: 0.018842620958089827\n",
      "\n",
      "[ Test epoch: 32 ]\n",
      "\n",
      "Test accuarcy: 0.7869\n",
      "Test average loss: 0.03926311105117202\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 11145.14862203598\n",
      "\n",
      "[ Train epoch: 33 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.019411806017160416\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.00963345542550087\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.02020205557346344\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.020112497732043266\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.03394334390759468\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.01360869687050581\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.011388471350073814\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.016475753858685493\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.018240172415971756\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.01895183138549328\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.013245553709566593\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.0125993387773633\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.0127666424959898\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.020320894196629524\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.029563402757048607\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.017006250098347664\n",
      "\n",
      "Train accuarcy: 79.404\n",
      "Train average loss: 0.01894409578680992\n",
      "\n",
      "[ Test epoch: 33 ]\n",
      "\n",
      "Test accuarcy: 0.7759\n",
      "Test average loss: 0.04103776826411486\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 11482.44368839264\n",
      "\n",
      "[ Train epoch: 34 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.02212197706103325\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.023432787507772446\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.017709070816636086\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.015168383717536926\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.9375\n",
      "Current train average loss: 0.011439282447099686\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.020609205588698387\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.02349211648106575\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.020810334011912346\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.011318567208945751\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.022009551525115967\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.026117829605937004\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.01771695353090763\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.01567877270281315\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.9375\n",
      "Current train average loss: 0.01249645370990038\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.013015465810894966\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.019076213240623474\n",
      "\n",
      "Train accuarcy: 79.19\n",
      "Train average loss: 0.019072630392611027\n",
      "\n",
      "[ Test epoch: 34 ]\n",
      "\n",
      "Test accuarcy: 0.7503\n",
      "Test average loss: 0.04495495875403285\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 11818.456426382065\n",
      "\n",
      "[ Train epoch: 35 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.018243342638015747\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.9375\n",
      "Current train average loss: 0.006724798586219549\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.027923107147216797\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.02874612994492054\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.02066352218389511\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.02033442258834839\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.013891556300222874\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.015412169508635998\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.019029464572668076\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.014664891175925732\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.029102684929966927\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.01824299246072769\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.020739950239658356\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.026084020733833313\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.020368991419672966\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.014370444230735302\n",
      "\n",
      "Train accuarcy: 79.468\n",
      "Train average loss: 0.018776539994180202\n",
      "\n",
      "[ Test epoch: 35 ]\n",
      "\n",
      "Test accuarcy: 0.8013\n",
      "Test average loss: 0.03738134553506971\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 12153.49146771431\n",
      "\n",
      "[ Train epoch: 36 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.022466149181127548\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.9375\n",
      "Current train average loss: 0.011872720904648304\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.010525374673306942\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.023643212392926216\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.01979708857834339\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.020107796415686607\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.01584654115140438\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.015839235857129097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.01370932161808014\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.019158123061060905\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.0158519484102726\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.028826795518398285\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.014416797086596489\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.01631965860724449\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.013029254041612148\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.020904183387756348\n",
      "\n",
      "Train accuarcy: 79.686\n",
      "Train average loss: 0.01869629814326763\n",
      "\n",
      "[ Test epoch: 36 ]\n",
      "\n",
      "Test accuarcy: 0.7499\n",
      "Test average loss: 0.04585821224302054\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 12489.978110790253\n",
      "\n",
      "[ Train epoch: 37 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.025877466425299644\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.010842720046639442\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.012022476643323898\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.016742099076509476\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.023980004712939262\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.027371445670723915\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.00913974642753601\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.019063979387283325\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.016033250838518143\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.011271068826317787\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.01930386573076248\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.028466999530792236\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.020526278764009476\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.01544597651809454\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.012896709144115448\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.0226637814193964\n",
      "\n",
      "Train accuarcy: 79.428\n",
      "Train average loss: 0.01893183836877346\n",
      "\n",
      "[ Test epoch: 37 ]\n",
      "\n",
      "Test accuarcy: 0.7564\n",
      "Test average loss: 0.046165118072926996\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 12825.28838634491\n",
      "\n",
      "[ Train epoch: 38 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.015100163407623768\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.017517738044261932\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.021097522228956223\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.011694245040416718\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.014069723896682262\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.014690679498016834\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.02407306246459484\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.01960356906056404\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.02406615950167179\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.028006020933389664\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.021329788491129875\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.02600759267807007\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.022231338545680046\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.018702158704400063\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.02994602546095848\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.017585720866918564\n",
      "\n",
      "Train accuarcy: 79.852\n",
      "Train average loss: 0.018635229710936545\n",
      "\n",
      "[ Test epoch: 38 ]\n",
      "\n",
      "Test accuarcy: 0.7869\n",
      "Test average loss: 0.03890009888485074\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 13159.05193567276\n",
      "\n",
      "[ Train epoch: 39 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.01496240496635437\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.013503378257155418\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.0192725770175457\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.015284652821719646\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.021760988980531693\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.020998306572437286\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.02337154559791088\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.02175162360072136\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.009879847057163715\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.9375\n",
      "Current train average loss: 0.008832182735204697\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.024278070777654648\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.022657789289951324\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.018105152994394302\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.021889232099056244\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.014175258576869965\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.02510812133550644\n",
      "\n",
      "Train accuarcy: 79.546\n",
      "Train average loss: 0.018789487961530685\n",
      "\n",
      "[ Test epoch: 39 ]\n",
      "\n",
      "Test accuarcy: 0.7623\n",
      "Test average loss: 0.04316557188928127\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 13492.832865476608\n",
      "\n",
      "[ Train epoch: 40 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.013725033961236477\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.013572970405220985\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.01601320691406727\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.023896541446447372\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.013130400329828262\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.024843808263540268\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.018328210338950157\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.017946209758520126\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.012142656370997429\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.014050771482288837\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.022830264642834663\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.019445639103651047\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.9375\n",
      "Current train average loss: 0.009518777951598167\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.015185831114649773\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.012001174502074718\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.018724732100963593\n",
      "\n",
      "Train accuarcy: 79.446\n",
      "Train average loss: 0.01885980664074421\n",
      "\n",
      "[ Test epoch: 40 ]\n",
      "\n",
      "Test accuarcy: 0.7258\n",
      "Test average loss: 0.051621082858741285\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 13827.290829896927\n",
      "\n",
      "[ Train epoch: 41 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.013813656754791737\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.96875\n",
      "Current train average loss: 0.008214049972593784\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.0158988144248724\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.021936867386102676\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.01695431023836136\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.013319828547537327\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.02046177349984646\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.028684666380286217\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.0166501235216856\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.014747987501323223\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.01594158262014389\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.035283710807561874\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.014084248803555965\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.01513124443590641\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.01547679677605629\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.018700508400797844\n",
      "\n",
      "Train accuarcy: 79.79\n",
      "Train average loss: 0.018667041469812393\n",
      "\n",
      "[ Test epoch: 41 ]\n",
      "\n",
      "Test accuarcy: 0.7609\n",
      "Test average loss: 0.044620586149394514\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 14159.775937795639\n",
      "\n",
      "[ Train epoch: 42 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.014740628190338612\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.02080301009118557\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.018896618857979774\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.01646808721125126\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.018027212470769882\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.015612687915563583\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.02669728919863701\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.015848349779844284\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.01736796833574772\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.02495000883936882\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.01858619973063469\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.018038185313344002\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.016346488147974014\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.01616879552602768\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.02821774035692215\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.024336887523531914\n",
      "\n",
      "Train accuarcy: 79.566\n",
      "Train average loss: 0.01867993418812752\n",
      "\n",
      "[ Test epoch: 42 ]\n",
      "\n",
      "Test accuarcy: 0.7871\n",
      "Test average loss: 0.03876264249160886\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 14496.871448993683\n",
      "\n",
      "[ Train epoch: 43 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.019966956228017807\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.02641552872955799\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.013063251972198486\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.020091071724891663\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.024746123701334\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.023786162957549095\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.027362443506717682\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.020141275599598885\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.01084853708744049\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.01865459978580475\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.01724010333418846\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.018266327679157257\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.011738354340195656\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.016840394586324692\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.027256179600954056\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.022282414138317108\n",
      "\n",
      "Train accuarcy: 79.662\n",
      "Train average loss: 0.01858071395546198\n",
      "\n",
      "[ Test epoch: 43 ]\n",
      "\n",
      "Test accuarcy: 0.7727\n",
      "Test average loss: 0.042262381983548404\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 14833.454986095428\n",
      "\n",
      "[ Train epoch: 44 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.02199449948966503\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.021867386996746063\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.01777169108390808\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.01965133473277092\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.0127255255356431\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.013973758555948734\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.02613929472863674\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.02467910386621952\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.02081136964261532\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.029805824160575867\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.012900160625576973\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.013865932822227478\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.0274050310254097\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.020257212221622467\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.02116531692445278\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.9375\n",
      "Current train average loss: 0.0062033324502408504\n",
      "\n",
      "Train accuarcy: 79.52\n",
      "Train average loss: 0.018711449201405047\n",
      "\n",
      "[ Test epoch: 44 ]\n",
      "\n",
      "Test accuarcy: 0.7697\n",
      "Test average loss: 0.041483324375748636\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 15169.393022537231\n",
      "\n",
      "[ Train epoch: 45 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.017340414226055145\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.018629269674420357\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.024308685213327408\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.026207180693745613\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.01899312250316143\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.010048429481685162\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.018487220630049706\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.016797160729765892\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.020436981692910194\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.013295711949467659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.008244328200817108\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.021876828745007515\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.023167306557297707\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.030684124678373337\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.021773047745227814\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.0128104779869318\n",
      "\n",
      "Train accuarcy: 79.836\n",
      "Train average loss: 0.01861192958444357\n",
      "\n",
      "[ Test epoch: 45 ]\n",
      "\n",
      "Test accuarcy: 0.7846\n",
      "Test average loss: 0.040517502947896716\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 15502.57317519188\n",
      "\n",
      "[ Train epoch: 46 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.023357952013611794\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.011610237881541252\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.023673327639698982\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.024979546666145325\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.02886298857629299\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.017973467707633972\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.013817996717989445\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.015156468376517296\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.024918239563703537\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.01974116452038288\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.019641980528831482\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.019903985783457756\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.031337689608335495\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.022915907204151154\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.03542802110314369\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.017240412533283234\n",
      "\n",
      "Train accuarcy: 79.978\n",
      "Train average loss: 0.018472227192521094\n",
      "\n",
      "[ Test epoch: 46 ]\n",
      "\n",
      "Test accuarcy: 0.7712\n",
      "Test average loss: 0.04145174314677715\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 15836.315245389938\n",
      "\n",
      "[ Train epoch: 47 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.015385566279292107\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.011143121868371964\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.025233730673789978\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.021931109949946404\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.019944775849580765\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.02686990424990654\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.01951013319194317\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.011674103327095509\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.018527893349528313\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.0194409117102623\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.010544423013925552\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.018818825483322144\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.013103705830872059\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.02084796503186226\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.015332943759858608\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.015454176813364029\n",
      "\n",
      "Train accuarcy: 79.776\n",
      "Train average loss: 0.018484320828914644\n",
      "\n",
      "[ Test epoch: 47 ]\n",
      "\n",
      "Test accuarcy: 0.76\n",
      "Test average loss: 0.044215382596105336\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 16170.351345539093\n",
      "\n",
      "[ Train epoch: 48 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.023512570187449455\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.017871888354420662\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.5625\n",
      "Current train average loss: 0.0358857698738575\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.010796017944812775\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.03090599551796913\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.013625447638332844\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.017561661079525948\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.014979114755988121\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.012405035085976124\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.01408467534929514\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.016781210899353027\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.01244837511330843\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.014587951824069023\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.02948344685137272\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.01840703748166561\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.010988535359501839\n",
      "\n",
      "Train accuarcy: 79.628\n",
      "Train average loss: 0.018650366649627687\n",
      "\n",
      "[ Test epoch: 48 ]\n",
      "\n",
      "Test accuarcy: 0.7782\n",
      "Test average loss: 0.04092261982411146\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 16503.336416721344\n",
      "\n",
      "[ Train epoch: 49 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.018405456095933914\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.015596546232700348\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.9375\n",
      "Current train average loss: 0.010190202854573727\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.01784038357436657\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.026795338839292526\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.014411400072276592\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.00998031534254551\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.02154303900897503\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.033182594925165176\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.018808089196681976\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.018775345757603645\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.022784849628806114\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.018634945154190063\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.019651729613542557\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.014273671433329582\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.020495224744081497\n",
      "\n",
      "Train accuarcy: 79.83\n",
      "Train average loss: 0.01841311421573162\n",
      "\n",
      "[ Test epoch: 49 ]\n",
      "\n",
      "Test accuarcy: 0.7972\n",
      "Test average loss: 0.03782588744312525\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 16837.583868980408\n",
      "\n",
      "[ Train epoch: 50 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.01683071069419384\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.01089998334646225\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.023667756468057632\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.032264258712530136\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.014107221737504005\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.018200216814875603\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.02575613372027874\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.019000569358468056\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.026295077055692673\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.030820976942777634\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.017125146463513374\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.59375\n",
      "Current train average loss: 0.03481599688529968\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.025611793622374535\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.008395378477871418\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.024882590398192406\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.02366841398179531\n",
      "\n",
      "Train accuarcy: 80.078\n",
      "Train average loss: 0.018264851181358097\n",
      "\n",
      "[ Test epoch: 50 ]\n",
      "\n",
      "Test accuarcy: 0.7865\n",
      "Test average loss: 0.040005975430458786\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 17167.528038740158\n",
      "\n",
      "[ Train epoch: 51 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.024874383583664894\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.9375\n",
      "Current train average loss: 0.008124406449496746\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.022713717073202133\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.02262786775827408\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.013356052339076996\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.018857266753911972\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.01036982610821724\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.016976967453956604\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.025380471721291542\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.009334069676697254\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.02254905179142952\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.042260147631168365\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.019281424582004547\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.015117342583835125\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.018695158883929253\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.021895285695791245\n",
      "\n",
      "Train accuarcy: 80.288\n",
      "Train average loss: 0.0184077098351717\n",
      "\n",
      "[ Test epoch: 51 ]\n",
      "\n",
      "Test accuarcy: 0.7794\n",
      "Test average loss: 0.04075983841493726\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 17499.438565969467\n",
      "\n",
      "[ Train epoch: 52 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.012475197203457355\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.01959691196680069\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.014805235899984837\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.01386683713644743\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.013208188116550446\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.013431491330265999\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.022216293960809708\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.018534183502197266\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.0154569735750556\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.02119755558669567\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.011436939239501953\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.020539287477731705\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.01799558848142624\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.01878075674176216\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.01258896291255951\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.014822936616837978\n",
      "\n",
      "Train accuarcy: 79.934\n",
      "Train average loss: 0.018406866989433765\n",
      "\n",
      "[ Test epoch: 52 ]\n",
      "\n",
      "Test accuarcy: 0.7618\n",
      "Test average loss: 0.04412674070745706\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 17828.014571666718\n",
      "\n",
      "[ Train epoch: 53 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.9375\n",
      "Current train average loss: 0.010596769861876965\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.012819782830774784\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.017882881686091423\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.0317641943693161\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.014824752695858479\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.016483714804053307\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.02146676927804947\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.02121196873486042\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.016065962612628937\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.011785008944571018\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.015097188763320446\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.02041127346456051\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.012657608836889267\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.018652405589818954\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.017049215734004974\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.022481560707092285\n",
      "\n",
      "Train accuarcy: 79.718\n",
      "Train average loss: 0.018533381709456443\n",
      "\n",
      "[ Test epoch: 53 ]\n",
      "\n",
      "Test accuarcy: 0.8017\n",
      "Test average loss: 0.03651807787269354\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 18159.225871562958\n",
      "\n",
      "[ Train epoch: 54 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.010524154640734196\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.018718430772423744\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.022088490426540375\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.019287075847387314\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.017612701281905174\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.017575694248080254\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.010354667901992798\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.0153942396864295\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.020208807662129402\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.027319543063640594\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.007186874747276306\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.019728675484657288\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.03732053562998772\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.01825692132115364\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.019066302105784416\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.010713048279285431\n",
      "\n",
      "Train accuarcy: 79.94\n",
      "Train average loss: 0.018431084360331296\n",
      "\n",
      "[ Test epoch: 54 ]\n",
      "\n",
      "Test accuarcy: 0.7955\n",
      "Test average loss: 0.03874949633702636\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 18491.84347677231\n",
      "\n",
      "[ Train epoch: 55 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.011078338138759136\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.013504983857274055\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.015090984292328358\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.019354067742824554\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.01762629672884941\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.01938563585281372\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.019451985135674477\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.017892131581902504\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.024245386943221092\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.014899952337145805\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.018109828233718872\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.023179765790700912\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.027015672996640205\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.024969864636659622\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.016002316027879715\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.013799631968140602\n",
      "\n",
      "Train accuarcy: 80.084\n",
      "Train average loss: 0.01828354448735714\n",
      "\n",
      "[ Test epoch: 55 ]\n",
      "\n",
      "Test accuarcy: 0.7858\n",
      "Test average loss: 0.04080345641300082\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 18822.425661563873\n",
      "\n",
      "[ Train epoch: 56 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.012625283561646938\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.01285160519182682\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.00967936310917139\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.01461946964263916\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.0152815543115139\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.015344417653977871\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.024257643148303032\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.011668010614812374\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.022376028820872307\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.025517769157886505\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.01520480029284954\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.65625\n",
      "Current train average loss: 0.033194221556186676\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.016383076086640358\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.018227916210889816\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.018054014071822166\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.01178920827805996\n",
      "\n",
      "Train accuarcy: 79.996\n",
      "Train average loss: 0.01831416634172201\n",
      "\n",
      "[ Test epoch: 56 ]\n",
      "\n",
      "Test accuarcy: 0.7807\n",
      "Test average loss: 0.0404934674102813\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 19153.54781603813\n",
      "\n",
      "[ Train epoch: 57 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.009800838306546211\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.028598569333553314\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.023992158472537994\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.016027765348553658\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.028802070766687393\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.011055530048906803\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.01418768148869276\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.017865756526589394\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.02243637479841709\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.015411623753607273\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.017239727079868317\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.016286084428429604\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.011968313716351986\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.71875\n",
      "Current train average loss: 0.016435815021395683\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.019457679241895676\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.009937761351466179\n",
      "\n",
      "Train accuarcy: 79.942\n",
      "Train average loss: 0.018372072521150112\n",
      "\n",
      "[ Test epoch: 57 ]\n",
      "\n",
      "Test accuarcy: 0.7702\n",
      "Test average loss: 0.04353164610937238\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 19483.48319220543\n",
      "\n",
      "[ Train epoch: 58 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.02113032154738903\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.01936413161456585\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.021151205524802208\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.0194780882447958\n",
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.014636082574725151\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.010972204618155956\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.0241817869246006\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.01850780099630356\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.023829923942685127\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.014676057733595371\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.022283172234892845\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.013130640611052513\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.017664169892668724\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.02233077958226204\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.016734132543206215\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.015788141638040543\n",
      "\n",
      "Train accuarcy: 80.184\n",
      "Train average loss: 0.01829801676660776\n",
      "\n",
      "[ Test epoch: 58 ]\n",
      "\n",
      "Test accuarcy: 0.7647\n",
      "Test average loss: 0.0428884733363986\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 19814.019614458084\n",
      "\n",
      "[ Train epoch: 59 ]\n",
      "\n",
      "Current batch: 0\n",
      "Current train accuracy: 0.90625\n",
      "Current train average loss: 0.015009766444563866\n",
      "\n",
      "Current batch: 100\n",
      "Current train accuracy: 0.96875\n",
      "Current train average loss: 0.009812557138502598\n",
      "\n",
      "Current batch: 200\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.016333257779479027\n",
      "\n",
      "Current batch: 300\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.01854400709271431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current batch: 400\n",
      "Current train accuracy: 0.6875\n",
      "Current train average loss: 0.03395833075046539\n",
      "\n",
      "Current batch: 500\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.013291574083268642\n",
      "\n",
      "Current batch: 600\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.02250618115067482\n",
      "\n",
      "Current batch: 700\n",
      "Current train accuracy: 0.8125\n",
      "Current train average loss: 0.016566937789320946\n",
      "\n",
      "Current batch: 800\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.01525313314050436\n",
      "\n",
      "Current batch: 900\n",
      "Current train accuracy: 0.9375\n",
      "Current train average loss: 0.012010387144982815\n",
      "\n",
      "Current batch: 1000\n",
      "Current train accuracy: 0.78125\n",
      "Current train average loss: 0.015267355367541313\n",
      "\n",
      "Current batch: 1100\n",
      "Current train accuracy: 0.84375\n",
      "Current train average loss: 0.015460487455129623\n",
      "\n",
      "Current batch: 1200\n",
      "Current train accuracy: 0.625\n",
      "Current train average loss: 0.03603803738951683\n",
      "\n",
      "Current batch: 1300\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.02268773317337036\n",
      "\n",
      "Current batch: 1400\n",
      "Current train accuracy: 0.875\n",
      "Current train average loss: 0.013216198422014713\n",
      "\n",
      "Current batch: 1500\n",
      "Current train accuracy: 0.75\n",
      "Current train average loss: 0.02025637961924076\n",
      "\n",
      "Train accuarcy: 80.308\n",
      "Train average loss: 0.018275220899879933\n",
      "\n",
      "[ Test epoch: 59 ]\n",
      "\n",
      "Test accuarcy: 0.7918\n",
      "Test average loss: 0.03857565416544676\n",
      "Model Saved\n",
      "\n",
      "Time elapsed: 20149.65588927269\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(0, 60):\n",
    "    #adjust_learning_rate(optimizer, epoch)\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "    print('\\nTime elapsed:', time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "602da3ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train_l = pd.DataFrame(train_losses, columns = ['train_losses'])\n",
    "df_train_l.plot(color = \"#ff0000\")\n",
    "plt.plot(df_train_l, marker = '*', color = 'r')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b328a078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train_a = pd.DataFrame(train_accuracy, columns = ['train_accuracy'])\n",
    "df_train_a.plot(color = \"#ff1111\")\n",
    "plt.plot(df_train_a, marker = '.', color = 'b')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "175ed897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test_l = pd.DataFrame(test_losses, columns = ['test_losses'])\n",
    "df_test_l.plot(color = \"#ff0000\")\n",
    "plt.plot(df_test_l, marker = '*', color = 'r')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a3c47ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_test_a = pd.DataFrame(test_accuracy, columns = ['test_accuracy'])\n",
    "df_test_a.plot(color = \"#ff0000\")\n",
    "plt.plot(df_test_a, marker = '*', color = 'r')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
